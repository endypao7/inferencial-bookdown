[["index.html", "Estadística Inferencial en Rstudio Lección 1 Conoce Rstudio 1.1 Instalación y Configuración de R-STUDIO 1.2 Primeros pasos 1.3 Conceptos básicos de programación en R:", " Estadística Inferencial en Rstudio Endy Paola Salon Lección 1 Conoce Rstudio 1.1 Instalación y Configuración de R-STUDIO 1.1.1 Rstudio en tu equipo (escritorio) Para comenzar a usar R, el primer paso es instalarlo en tu computadora. R es compatible con casi todas las plataformas, incluyendo los sistemas operativos más comunes. Windows, Mac OS X y Linux. Links de descarga para y RStudio. Nota: Antes de instalar Rstudio, debes instalar R (el motor) RStudio es un entorno de desarrollo integrado (IDE) disponible para R, el cual tiene un buen editor con resaltado de sintaxis, un visor de objetos de R y un gran número de características agradables que están integradas.Ademas, esta dedicado a la computación estadística y gráficos. Otra opción: Rstudio en la nube Puedes utilizar Rstudio en cualquier dispositivo conectado a internet y guardar todos tus archivos en la nube. Encontras todo tal como lo dejaste en cualquier equipo. Recuerda que esta versión tiene un límite de horas de uso mensual. Link de acceso a RStudio Cloud 1.2 Primeros pasos Rscript Puede resultar de mucha utilidad trabajar y guardar los comandos usados en un “script” de R. El script es básicamente un documento de texto donde puedes ir escribiendo todos los comandos a ejecutar, es la hoja de ruta que el programa seguirá para analizar tus datos. Considera el hecho de que si se antepone a una línea de comando el signo #, este no será ejecutado y el programa lo considerará como un comentario. Paquetes o librerías en R Las librerías en R son colecciones de funciones, datos y documentación que amplían las capacidades del lenguaje base. También se les llama paquetes (packages). Estas librerías permiten a los usuarios realizar análisis de datos, visualización, modelado estadístico, aprendizaje automático, entre otras tareas, sin necesidad de programar todo desde cero. Ejemplo: “Mundo” Tidyverse en R-Studio El Tidyverse es una colección de paquetes del R que permiten preparar, procesar y graficar bases de datos. Se destacan los siguientes: ggplot: permite crear visualizaciones elegantes de los datos de una manera relativamente sencilla. stringr: permite manipular cadenas de caracteres con el fin de realizar sustituciones, detectar duplicados, analizar patrones, etc. tidyr: tiene como objetivo obtener datos ordenados. Destacan funciones como gather para crear factores con base en nombres de columnas y separate para crear factores separando los caracteres de una columna. readr: permite importar y exportar bases de datos en diferentes formatos y tiene implementada la función problems que detecta problemas en nuestras bases. Para más información visitar la página web: https://www.tidyverse.org/packages/ Para instalar librerías: Install.pachages(“nombre de la librería”) por primera vez y para llamarla o utilizarla library(nombre de la librería) o en su defecto, require(nombre de la librería) # Instalar la librería (solo la primera vez) #install.packages(&quot;tidyverse&quot;) # Cargar la librería library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 4.0.0 ✔ tibble 3.3.0 ## ✔ lubridate 1.9.4 ✔ tidyr 1.3.1 ## ✔ purrr 1.0.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors 1.2.1 Creación de reportes en R con R Markdown: R Markdown es un formato de documento que combina código R, texto y visualizaciones en un solo archivo, permitiendo generar informes dinámicos en varios formatos como HTML, PDF y Word. Es ampliamente utilizado en análisis de datos, reportes automatizados y documentación reproducible. Se basa en el lenguaje Markdown para formatear el texto y en R para ejecutar código dentro del documento. ¿Cómo funciona Rmarkdown? En RStudio, ve a File &gt; New File &gt; R Markdown Selecciona el formato de salida (HTML, PDF, Word). Se generará un archivo con extensión .Rmd. Un archivo .Rmd tiene tres partes principales: Encabezado YAML: Define el título, autor y formato de salida. Texto en Markdown: Usa sintaxis Markdown para formatear el contenido. Chunks de código R: Secciones de código R que pueden ejecutarse y mostrar resultados. Si escribes sobre este tipo de ventana, estarás generando solo texto, pero puedes incluir chunks o “trozos” de código a lo largo de todo tu trabajo y crear informes como este que estas leyendo. Renderizar el documento Para generar el documento final, haz clic en “Knit” en RStudio. Selecciona el formato de salida (HTML, PDF o Word). Se creará un archivo con los resultados y el código ejecutado. 1.3 Conceptos básicos de programación en R: Si quieres aprender R, primero necesitas entender cómo funcionan los lenguajes de programación en general Todos los lenguajes (incluyendo R) tienen ciertas bases comunes: Variables → Almacenan datos. Operadores → Realizan cálculos o comparaciones. Estructuras de control → Permiten tomar decisiones y repetir tareas. Funciones → Agrupan código reutilizable. Creación de Objetos R es un lenguaje orientado a objetos. Los objetos pueden ser usados para guardar valores y pueden madificarse mediante funciones como por ejemplo sumar dos objetos o calcular la media. X &lt;- 4 Y &lt;- 2 X+Y ## [1] 6 R como calculadora Puedes hacer operaciones matemáticas básicas como +, -, *, /. - También puedes calcular potencias (^), raíces cuadradas (sqrt()), logaritmos (log()) y funciones trigonométricas (sin(), cos(), tan()). - print() se usa para mostrar los resultados en la consola. Prueba este código en RStudio y verás cómo R funciona como una calculadora avanzada. # Operaciones básicas 5 + 3 # Suma ## [1] 8 10 - 4 # Resta ## [1] 6 6 * 7 # Multiplicación ## [1] 42 20 / 5 # División ## [1] 4 # Potencias y raíces 2^3 # 2 elevado a la 3 ## [1] 8 sqrt(16) # Raíz cuadrada de 16 ## [1] 4 # Operaciones avanzadas log(100, base = 10) # Logaritmo base 10 ## [1] 2 exp(2) # e^2 ## [1] 7.389056 sin(pi / 2) # Seno de 90 grados (π/2 radianes) ## [1] 1 1.3.1 Tipos de variables en R: Tipo Ejemplo Descripción Numeric 3.14, -2.5 Números con decimales Integer 10L, -5L Números enteros Character \"Hola\" Texto o cadenas de caracteres Logical TRUE, FALSE Valores lógicos (booleanos) Factor factor(\"azul\", \"rojo\") Variables categóricas Date as.Date(\"2024-02-05\") Fechas POSIXct as.POSIXct(\"2024-02-05 14:30:00\") Fechas y horas # Numéricas (Numeric) num &lt;- 3.14 # Número decimal class(num) ## [1] &quot;numeric&quot; # Enteros (Integer) entero &lt;- 10L # Número entero class(entero) ## [1] &quot;integer&quot; # Cadenas de Texto (Character) texto &lt;- &quot;Hola, mundo&quot; class(texto) ## [1] &quot;character&quot; # Lógicos (Logical) logico &lt;- TRUE class(logico) ## [1] &quot;logical&quot; # Factores (Factor) colores &lt;- factor(c(&quot;rojo&quot;, &quot;azul&quot;, &quot;verde&quot;, &quot;rojo&quot;)) class(colores) ## [1] &quot;factor&quot; levels(colores) # Ver categorías ## [1] &quot;azul&quot; &quot;rojo&quot; &quot;verde&quot; # Fechas y Tiempos (Date y POSIXct) fecha &lt;- as.Date(&quot;2024-02-05&quot;) # Convertir a fecha hora &lt;- as.POSIXct(&quot;2024-02-05 14:30:00&quot;) # Fecha y hora class(fecha) ## [1] &quot;Date&quot; class(hora) ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; Nota: La función class permite ver qué tipo de variable estamos utilizando 1.3.2 Estructuras de Datos en R: En R, los datos se pueden organizar en diferentes estructuras según la forma en que se almacena y manipula la información. Estructura Descripción Ejemplo Vector Secuencia de elementos del mismo tipo c(1, 2, 3, 4, 5) Matrix Tabla bidimensional con el mismo tipo de dato matrix(1:9, nrow = 3, ncol = 3) List Contiene diferentes tipos de datos list(nombre = \"Ana\", edad = 25) Data Frame Tabla con columnas de diferentes tipos data.frame(Nombre = c(\"Ana\", \"Carlos\"), Edad = c(25, 30)) Factor Variable categórica con niveles factor(c(\"rojo\", \"azul\", \"verde\")) Array Estructura multidimensional array(1:8, dim = c(2,2,2)) Vectores # Vector numérico vector &lt;- c(1, 2, 3, 4, 5) vector ## [1] 1 2 3 4 5 # Vector de caracteres caracteres&lt;- c(&quot;rojo&quot;, &quot;azul&quot;, &quot;verde&quot;) caracteres ## [1] &quot;rojo&quot; &quot;azul&quot; &quot;verde&quot; # Vector lógico logico &lt;- c(TRUE, FALSE, TRUE) logico ## [1] TRUE FALSE TRUE # Mostrar tipo class(vector) ## [1] &quot;numeric&quot; Factor # Crear un factor con categorías colores &lt;- factor(c(&quot;rojo&quot;, &quot;azul&quot;, &quot;verde&quot;, &quot;rojo&quot;)) # Ver niveles levels(colores) ## [1] &quot;azul&quot; &quot;rojo&quot; &quot;verde&quot; Matriz # Crear una matriz 3x3 con números del 1 al 9 matriz &lt;- matrix(1:9, nrow = 3, ncol = 3) matriz ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 # Mostrar matriz print(matriz) ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 Lista Puede contener diferentes tipos de datos (vectores, matrices, data frames, etc.). # Crear una lista con diferentes tipos de datos mi_lista &lt;- list(nombre = &quot;Ana&quot;, edad = 25, notas = c(9, 8, 10)) # Mostrar contenido de la lista print(mi_lista) ## $nombre ## [1] &quot;Ana&quot; ## ## $edad ## [1] 25 ## ## $notas ## [1] 9 8 10 Dataframe Es una tabla donde cada columna puede tener diferentes tipos de datos. Es la estructura más utilizada en análisis de datos. # Crear un data frame df &lt;- data.frame(Nombre = c(&quot;Ana&quot;, &quot;Carlos&quot;, &quot;Luis&quot;), Edad = c(25, 30, 22), Aprobado = c(TRUE, FALSE, TRUE)) # Mostrar data frame df ## Nombre Edad Aprobado ## 1 Ana 25 TRUE ## 2 Carlos 30 FALSE ## 3 Luis 22 TRUE Condicional if-else. En R, la sintáxis del condicional consiste en: if (A): evalúa si se cumple la condición A. else if (B): si no se cumple la condición o condiciones anteriores, entonces evalúe si se cumple la condición B. else: si no se cumple ninguna de las condiciones anteriores entonces haga lo siguiente. Ejemplo: a&lt;-9 if (a&lt;0){ print(&quot;a es negativo&quot;) }else if (a&gt;0){ print(&quot;a es positivo&quot;) }else{ print(&quot;a es igual a cero&quot;) } ## [1] &quot;a es positivo&quot; Bucles for: Usado para repetir un bloque específico de código, siguiendo una secuencia dada. suma&lt;-0 for (i in 1:10){ suma&lt;-suma+i } suma ## [1] 55 Operadores de comparación en R: # Asignación de valores a &lt;- 1 b &lt;- 3 # Operaciones y comentarios explicativos # ¿b es diferente de a? b != a # TRUE ## [1] TRUE # ¿es a igual a b? isTRUE(a == b) # FALSE ## [1] FALSE # Negar que a es menor que b !(a &lt; b) # FALSE ## [1] FALSE # ¿es a menor que b o b menor que a? (a &lt; b | b &lt; a) # TRUE ## [1] TRUE # ¿es a menor o igual a b o b igual a a? (a &lt;= b &amp; b == a) # FALSE ## [1] FALSE "],["exploración-y-análisis-de-datos-eda.html", "Lección 2 Exploración y Análisis de Datos (EDA) 2.1 Dataframes (bases de datos) 2.2 Pre procesamiento de una Base de Datos Preinstalada en R 2.3 Análilsis exploratorio de Datos (EDA) básico", " Lección 2 Exploración y Análisis de Datos (EDA) Aquí encontraras las herramientas básicas para realizar un análisis exploratorio de Datos en Rstudio.El objetivo es conocer la información, qué primeras impresiones o tendencias mrevelan los datos. 2.1 Dataframes (bases de datos) Un dataframe en Rstudio es una estructura de datos similar a una tabla o base de datos, donde las columnas representan variables y las filas representan observaciones. 2.1.1 Creación de Dataframes Es posible crear un dataframe a partir de la unión de vectores con la función data.frame(). #Vectores o listas nombre = c(&quot;Ana&quot;, &quot;Luis&quot;, &quot;Carlos&quot;, &quot;Sofia&quot;) edad = c(23, 25, 30, 22) ciudad = c(&quot;Bogota&quot;, &quot;Medellin&quot;, &quot;Cali&quot;, &quot;Barranquilla&quot;) ingresos = c(2500000, 3000000, 2800000, 2700000) # Crear un dataframe manualmente df &lt;- data.frame(nombre,edad,ciudad,ingresos) # Ver el dataframe df ## nombre edad ciudad ingresos ## 1 Ana 23 Bogota 2500000 ## 2 Luis 25 Medellin 3000000 ## 3 Carlos 30 Cali 2800000 ## 4 Sofia 22 Barranquilla 2700000 Acceso a los Datos del dataframe Para acceder a las columnas de un dataframe existen varias maneras # Acceder a una columna específica df$nombre ## [1] &quot;Ana&quot; &quot;Luis&quot; &quot;Carlos&quot; &quot;Sofia&quot; # Acceder a una fila específica df[2, ] ## nombre edad ciudad ingresos ## 2 Luis 25 Medellin 3e+06 # Acceder a una celda específica df[3, 2] ## [1] 30 Modificación de Dataframes Es posible agregar, modificar o eliminar columnas y filas en un dataframe Agregar una nueva columna # Agregar una nueva columna df$puntaje &lt;- c(85, 90, 78, 88) df ## nombre edad ciudad ingresos puntaje ## 1 Ana 23 Bogota 2500000 85 ## 2 Luis 25 Medellin 3000000 90 ## 3 Carlos 30 Cali 2800000 78 ## 4 Sofia 22 Barranquilla 2700000 88 Modificar un valor # Modificar un valor df$ingresos[1] &lt;- 2600000 Eliminar una columna # Eliminar una columna df$ciudad &lt;- NULL df ## nombre edad ingresos puntaje ## 1 Ana 23 2600000 85 ## 2 Luis 25 3000000 90 ## 3 Carlos 30 2800000 78 ## 4 Sofia 22 2700000 88 Filtrado de Datos También, es posible filtrar filas que cumplen ciertas condiciones: # Filtrar personas con ingresos mayores a 2.8 millones subset(df, ingresos &gt; 2800000) ## nombre edad ingresos puntaje ## 2 Luis 25 3e+06 90 # Filtrar personas con puntaje mayor a 80 df[df$puntaje &gt; 80, ] ## nombre edad ingresos puntaje ## 1 Ana 23 2600000 85 ## 2 Luis 25 3000000 90 ## 4 Sofia 22 2700000 88 Ordenamiento de Dataframes # Ordenar por edad df_ordenado &lt;- df[order(df$edad), ] df_ordenado ## nombre edad ingresos puntaje ## 4 Sofia 22 2700000 88 ## 1 Ana 23 2600000 85 ## 2 Luis 25 3000000 90 ## 3 Carlos 30 2800000 78 Guardar Dataframes Guardar un dataframe como un archivo CSV (Este es un formato muy común en el que se suelen encontrar las bases de datos): # Guardar dataframe en un archivo CSV write.csv(df, &quot;datos.csv&quot;, row.names = FALSE) help(&quot;write.csv&quot;) ## starting httpd help server ... done 2.1.2 Importar un Dataframe desde un archivo CSV # Leer un archivo CSV df_importado &lt;- read.csv(&quot;datos.csv&quot;) df_importado ## nombre edad ingresos puntaje ## 1 Ana 23 2600000 85 ## 2 Luis 25 3000000 90 ## 3 Carlos 30 2800000 78 ## 4 Sofia 22 2700000 88 Otra forma para importar datos, es a través de la ventana de archivos body { text-align: justify; } También es posible importar datos directamente desde donde esté guardada la base de datos en el equipo (cuando se utiliza la versión Rstudio de escritorio) La línea de código sería la siguiente: 2.2 Pre procesamiento de una Base de Datos Preinstalada en R R incluye varias bases de datos preinstaladas. En este ejemplo, usaremos mtcars, una base de datos con información sobre automóviles. # Cargar la base de datos mtcars data(&quot;mtcars&quot;) datos &lt;- mtcars head(datos)# Ver las primeras filas ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Exploración de Datos Para ver las dimensiones del dataframe o el tamaño de mi base de datos: # Dimensiones del dataframe dim(datos) ## [1] 32 11 Ver los tipos de datos o variables # Ver estructura de los datos str(datos) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... Hacer un resumen estadístico (muy general). Esta es la primera impresión de todas las variables # Resumen estadístico general summary(datos) ## mpg cyl disp hp ## Min. :10.40 Min. :4.000 Min. : 71.1 Min. : 52.0 ## 1st Qu.:15.43 1st Qu.:4.000 1st Qu.:120.8 1st Qu.: 96.5 ## Median :19.20 Median :6.000 Median :196.3 Median :123.0 ## Mean :20.09 Mean :6.188 Mean :230.7 Mean :146.7 ## 3rd Qu.:22.80 3rd Qu.:8.000 3rd Qu.:326.0 3rd Qu.:180.0 ## Max. :33.90 Max. :8.000 Max. :472.0 Max. :335.0 ## drat wt qsec vs ## Min. :2.760 Min. :1.513 Min. :14.50 Min. :0.0000 ## 1st Qu.:3.080 1st Qu.:2.581 1st Qu.:16.89 1st Qu.:0.0000 ## Median :3.695 Median :3.325 Median :17.71 Median :0.0000 ## Mean :3.597 Mean :3.217 Mean :17.85 Mean :0.4375 ## 3rd Qu.:3.920 3rd Qu.:3.610 3rd Qu.:18.90 3rd Qu.:1.0000 ## Max. :4.930 Max. :5.424 Max. :22.90 Max. :1.0000 ## am gear carb ## Min. :0.0000 Min. :3.000 Min. :1.000 ## 1st Qu.:0.0000 1st Qu.:3.000 1st Qu.:2.000 ## Median :0.0000 Median :4.000 Median :2.000 ## Mean :0.4062 Mean :3.688 Mean :2.812 ## 3rd Qu.:1.0000 3rd Qu.:4.000 3rd Qu.:4.000 ## Max. :1.0000 Max. :5.000 Max. :8.000 Verificación y Manejo de Datos Faltantes Verificar: # Verificar valores faltantes sum(is.na(datos)) ## [1] 0 Eliminar: # Si hubiera valores NA, podríamos eliminarlos con: df &lt;- na.omit(datos) La solución a los datos faltantes NO SIEMPRE va a ser eliminarlos. Es muy importante dar el tratamiento correcto. Eliminación de Columnas Innecesarias Si algunas columnas no son relevantes para el análisis, es posible eliminarlas. # Eliminar la columna &#39;carb&#39; datos ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 datos$carb &lt;- NULL head(datos) ## mpg cyl disp hp drat wt qsec vs am gear ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 Filtrado de Datos Se pueden filtrar observaciones basadas en condiciones específicas. # Filtrar autos con más de 20 millas por galón (mpg) df_filtrado &lt;- subset(datos, mpg &gt; 20) df_filtrado ## mpg cyl disp hp drat wt qsec vs am gear ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 Transformación de Datos Podemos agregar columnas nuevas basadas en cálculos. # Crear una nueva columna con consumo en km por litro datos$km_per_l &lt;- datos$mpg * 0.425144 head(datos) ## mpg cyl disp hp drat wt qsec vs am gear km_per_l ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 8.928024 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 8.928024 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 9.693283 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 9.098082 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 7.950193 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 7.695106 Cambio de Tipo de Variable Podemos convertir una variable numérica en categórica. str(datos) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp : num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat : num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec : num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear : num 4 4 4 3 3 3 3 4 4 4 ... ## $ km_per_l: num 8.93 8.93 9.69 9.1 7.95 ... # Convertir la variable &#39;cyl&#39; (cilindros) en factor datos$cyl &lt;- as.factor(datos$cyl) # Ver estructura para confirmar el cambio str(datos) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : Factor w/ 3 levels &quot;4&quot;,&quot;6&quot;,&quot;8&quot;: 2 2 1 2 3 2 3 1 1 2 ... ## $ disp : num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat : num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec : num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear : num 4 4 4 3 3 3 3 4 4 4 ... ## $ km_per_l: num 8.93 8.93 9.69 9.1 7.95 ... Ordenamiento de Datos # Ordenar por caballos de fuerza (hp) df_ordenado &lt;- datos[order(datos$hp), ] head(df_ordenado) ## mpg cyl disp hp drat wt qsec vs am gear km_per_l ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 12.92438 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 10.37351 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 14.41238 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 13.77467 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 11.60643 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 11.05374 Actividades para practicar Crea un dataframe con datos de 5 amigos, incluyendo nombre, edad y ciudad. Filtra las personas mayores de 25 años. Agrega una nueva columna con su ocupación. Guarda el dataframe en un archivo CSV y vuelve a importarlo en R. 2.3 Análilsis exploratorio de Datos (EDA) básico El análisis exploratorio de datos (Ver video) (EDA por sus siglas en inglés) implica el uso de gráficos y visualizaciones para explorar y analizar un conjunto de datos. El objetivo es explorar, investigar y aprender, no confirmar hipótesis estadísticas. ¿Cuándo debo utilizarlo? El análisis exploratorio de datos es una potente herramienta para explorar un conjunto de datos. Incluso cuando su objetivo es efectuar análisis planificados, el EDA puede utilizarse para limpiar datos, para análisis de subgrupos o simplemente para comprender mejor los datos. Un paso inicial importante en cualquier análisis de datos es representar los datos gráficamente. No gráfico: Calcula estadísticas descriptivas de las variables Gráfico: Calcula estadísticas de forma gráfica Univariado: Analiza una sola variable a la vez Multivariado: Analiza dos o más variables A su vez, cada uno de esas dividisiones puede subdividirse según los tipos de datos con los que trabajemos: categóricos o numéricos. 2.3.1 Ejemplo (Contexto): El presente estudio se basa en una encuesta aplicada a una muestra representativa de 500 ciudadanos de la ciudad de Springfield, con el objetivo de analizar su nivel de confianza en el gobierno, entre otras. Además, se examina el impacto de las redes sociales en la formación de la opinión pública y su posible influencia en el comportamiento electoral. Para garantizar la calidad de los datos y obtener conclusiones válidas, es necesario realizar un Análisis Exploratorio de Datos (EDA) antes de proceder con cualquier modelado estadístico o inferencia. La base de datos contiene las siguientes variables: Variable Tipo de Variable Categoría/Tipo Descripción Edad Numérica Continua Años cumplidos Género Categórica Nominal Identificación de género (Masculino, Femenino, No Binario) Nivel de Educación Categórica Ordinal Último nivel educativo alcanzado (Primaria, Secundaria, Universitaria, Posgrado) Ingreso Mensual Numérica Continua Ingresos mensuales en moneda local Interés en Política Categórica Ordinal Nivel de interés en política (Escala Likert del 1 al 5) Frecuencia de Voto Categórica Ordinal Frecuencia con la que vota (Nunca, A veces, Siempre) Ideología Política Categórica Nominal Identificación ideológica (Izquierda, Centro, Derecha) Confianza en el Gobierno Categórica Ordinal Nivel de confianza en el gobierno (Escala Likert del 1 al 10) Uso de Redes para Informarse Categórica Ordinal Nivel de uso de redes sociales para informarse (Bajo, Medio, Alto) Participación en Protestas Categórica Nominal Si ha participado en protestas (Sí, No) Instalar y Cargar paquetes Lo primero que tenemos que hacer es cargar los paquetes que vamos a utilizar para el análisis. En este caso vamos a usar: library(tidyverse)# Incluye paquetes de importación, visualización entre otros library(dplyr)# Manipulación de Datos library(ggplot2)# Visualización de datos library(readxl)# Importación de datos library(tibble)# Tablas library(readr) #Para cargar la base de datos Si no ha instalado estos paquetes debe correr primero el comando: install.packages(\"nombre del paquete\"), Recuerde que los paquetes deben instalarse una única vez, posteriormente se pueden llamar utilizando la función “library” 2.3.2 Cargar base de datos: Tenga en cuenta que debe utilizar la dirección de donde está guardada la base de datos en caso de usar Rstudio descargado en su equipo, o importarlo en la carpeta files en caso de estar trabajando en Rstudio cloud. Aquí puede ir a un video acerca de importación de datos o datasets: (Ver video para Rstudio de escritorio) o también (Ver video para Rstudio Cloud)** datos &lt;- read_csv(&quot;DATA/dataset_opinion_publica.csv&quot;) #Ojo esta es la dirección en la que la profe tenía guardados sus datos, es necesario cambiarla. ## Rows: 500 Columns: 10 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (6): genero, nivel_de_educacion, frecuencia_de_voto, ideologia_politica,... ## dbl (4): edad, ingreso_mensual, interes_en_politica, confianza_en_gobierno ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Nombres de variables Aquí podemos ver qué variables fueron importadas en nuestro Data Frame: names(datos)# nombres de variables ## [1] &quot;edad&quot; &quot;genero&quot; ## [3] &quot;nivel_de_educacion&quot; &quot;ingreso_mensual&quot; ## [5] &quot;interes_en_politica&quot; &quot;frecuencia_de_voto&quot; ## [7] &quot;ideologia_politica&quot; &quot;confianza_en_gobierno&quot; ## [9] &quot;uso_de_redes_informarse&quot; &quot;participacion_protestas&quot; Mostrar o llamar una variable head(datos$nivel_de_educacion) #Se utiliza el simbilo $ despues del nombre de la base. Se uba la función head para mostrar solo los primero sdatos y no todos. ## [1] &quot;Secundaria&quot; &quot;Universitaria&quot; &quot;Universitaria&quot; &quot;Posgrado&quot; ## [5] &quot;Universitaria&quot; &quot;Universitaria&quot; Dimensiones Es importante conocer las dimensiones del Dataset cargado para asegurarse que se incluyeron todas las variables y observaciones. dim(datos) #Dimensiones: num filas x num columnas ## [1] 500 10 Mostrar las primeras filas de la base de datos head(datos) ## # A tibble: 6 × 10 ## edad genero nivel_de_educacion ingreso_mensual interes_en_politica ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 56 Femenino Secundaria 2333. 4 ## 2 69 No binario Universitaria 1692. 1 ## 3 46 Masculino Universitaria 6550. 3 ## 4 32 Masculino Posgrado 3327. 1 ## 5 60 Femenino Universitaria 5944. 5 ## 6 25 Masculino Universitaria 4389. 4 ## # ℹ 5 more variables: frecuencia_de_voto &lt;chr&gt;, ideologia_politica &lt;chr&gt;, ## # confianza_en_gobierno &lt;dbl&gt;, uso_de_redes_informarse &lt;chr&gt;, ## # participacion_protestas &lt;chr&gt; Tipos de datos Con esto es posible verificar que los datos están correctamente cargados de acuerdo a la naturaleza de cada variable: str(datos) ## spc_tbl_ [500 × 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ edad : num [1:500] 56 69 46 32 60 25 78 38 56 75 ... ## $ genero : chr [1:500] &quot;Femenino&quot; &quot;No binario&quot; &quot;Masculino&quot; &quot;Masculino&quot; ... ## $ nivel_de_educacion : chr [1:500] &quot;Secundaria&quot; &quot;Universitaria&quot; &quot;Universitaria&quot; &quot;Posgrado&quot; ... ## $ ingreso_mensual : num [1:500] 2333 1692 6550 3327 5944 ... ## $ interes_en_politica : num [1:500] 4 1 3 1 5 4 7 5 10 4 ... ## $ frecuencia_de_voto : chr [1:500] &quot;A veces&quot; &quot;Siempre&quot; &quot;Siempre&quot; &quot;Siempre&quot; ... ## $ ideologia_politica : chr [1:500] &quot;Centro&quot; &quot;Derecha&quot; &quot;Centro&quot; &quot;Centro&quot; ... ## $ confianza_en_gobierno : num [1:500] 1 6 5 9 2 8 5 2 10 6 ... ## $ uso_de_redes_informarse: chr [1:500] &quot;Alto&quot; &quot;Medio&quot; &quot;Medio&quot; &quot;Alto&quot; ... ## $ participacion_protestas: chr [1:500] &quot;No&quot; &quot;No&quot; &quot;No&quot; &quot;No&quot; ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. edad = col_double(), ## .. genero = col_character(), ## .. nivel_de_educacion = col_character(), ## .. ingreso_mensual = col_double(), ## .. interes_en_politica = col_double(), ## .. frecuencia_de_voto = col_character(), ## .. ideologia_politica = col_character(), ## .. confianza_en_gobierno = col_double(), ## .. uso_de_redes_informarse = col_character(), ## .. participacion_protestas = col_character() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; Supongamos que las variables Interés en política y Confianza en el gobierno se deben manejar como variables categóricas, pero R las lee como numéricas. Es posible cambiar el tipo de variable: #Convertir variables en factores datos$interes_en_politica &lt;- as.factor(datos$interes_en_politica) #OJO: con el signo &quot;$&quot; llamo a una variable específica de mi dataset datos$confianza_en_gobierno &lt;- as.factor(datos$confianza_en_gobierno) Revisar nuevamente el Dataset: str(datos) ## spc_tbl_ [500 × 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ edad : num [1:500] 56 69 46 32 60 25 78 38 56 75 ... ## $ genero : chr [1:500] &quot;Femenino&quot; &quot;No binario&quot; &quot;Masculino&quot; &quot;Masculino&quot; ... ## $ nivel_de_educacion : chr [1:500] &quot;Secundaria&quot; &quot;Universitaria&quot; &quot;Universitaria&quot; &quot;Posgrado&quot; ... ## $ ingreso_mensual : num [1:500] 2333 1692 6550 3327 5944 ... ## $ interes_en_politica : Factor w/ 10 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 4 1 3 1 5 4 7 5 10 4 ... ## $ frecuencia_de_voto : chr [1:500] &quot;A veces&quot; &quot;Siempre&quot; &quot;Siempre&quot; &quot;Siempre&quot; ... ## $ ideologia_politica : chr [1:500] &quot;Centro&quot; &quot;Derecha&quot; &quot;Centro&quot; &quot;Centro&quot; ... ## $ confianza_en_gobierno : Factor w/ 10 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 6 5 9 2 8 5 2 10 6 ... ## $ uso_de_redes_informarse: chr [1:500] &quot;Alto&quot; &quot;Medio&quot; &quot;Medio&quot; &quot;Alto&quot; ... ## $ participacion_protestas: chr [1:500] &quot;No&quot; &quot;No&quot; &quot;No&quot; &quot;No&quot; ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. edad = col_double(), ## .. genero = col_character(), ## .. nivel_de_educacion = col_character(), ## .. ingreso_mensual = col_double(), ## .. interes_en_politica = col_double(), ## .. frecuencia_de_voto = col_character(), ## .. ideologia_politica = col_character(), ## .. confianza_en_gobierno = col_double(), ## .. uso_de_redes_informarse = col_character(), ## .. participacion_protestas = col_character() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; 2.3.3 Revisión de valores faltantes (N/A): Sumar N/As por cada columna (variable) # Contar valores faltantes por variable colSums(is.na(datos)) ## edad genero nivel_de_educacion ## 0 0 0 ## ingreso_mensual interes_en_politica frecuencia_de_voto ## 10 0 0 ## ideologia_politica confianza_en_gobierno uso_de_redes_informarse ## 10 0 0 ## participacion_protestas ## 10 Nota importante: Cuando se identifican datos faltantes en un conjunto de datos durante un Análisis Exploratorio de Datos (EDA), es fundamental evaluar su impacto en el análisis y decidir el mejor método para tratarlos. El primer paso consiste en cuantificar la cantidad de valores ausentes y analizar su distribución a lo largo de las variables. Si los valores perdidos son escasos y aleatorios, una opción válida puede ser eliminarlos sin afectar significativamente los resultados. Sin embargo, cuando los valores faltantes son numerosos o siguen un patrón sistemático, es recomendable aplicar métodos de imputación, como el reemplazo por la media o mediana en variables numéricas, o el uso de la moda en variables categóricas. También pueden emplearse técnicas más avanzadas, como la imputación por regresión o el uso de modelos de aprendizaje automático. En cualquier caso, la decisión sobre el tratamiento de los datos ausentes debe tomarse considerando el contexto del estudio y asegurando que no se introduzcan sesgos que afecten la validez de las conclusiones. 2.3.4 Revisión de valores atípicos (outliers) Nota importante: La detección de valores atípicos es un paso crucial en un Análisis Exploratorio de Datos (EDA), ya que estos pueden influir en la interpretación de los resultados y en la robustez de los modelos estadísticos. Un valor atípico es una observación que se aleja significativamente del resto de los datos y puede ser causado por errores de medición, registros incorrectos o, en algunos casos, por la naturaleza de la propia distribución de los datos. Para identificarlos, se pueden utilizar técnicas gráficas como los gráficos de caja y bigotes. Una vez detectados, es importante analizar su origen: si los valores son producto de errores, pueden ser corregidos o eliminados; si son casos extremos pero válidos, se pueden utilizar transformaciones más complejas para reducir su impacto. La decisión de mantener, corregir o eliminar valores atípicos debe basarse en la naturaleza del problema y el contexto del estudio, asegurando que el análisis refleje con precisión la realidad de los datos. Un resumen estadístico general de las variables nos puede mostrar el resumen de los cinco números para las variables numéricas: (mínimo, primer cuartil, segundo cuartil (que equivale a la mediana), tercer cuartil y valor máximo). Estos cinco números nos brindan una idea de la distribución de los datos: la media se ve alterada por valores extremos, mientras que la mediana no, cuando la media se aleja mucho de la mediana, puede ser un indicador de datos atípicos o extremos. En este caso, las variables numéricas son Edad e Ingreso mensual: # Resumen estadístico general summary(datos) ## edad genero nivel_de_educacion ingreso_mensual ## Min. :18.00 Length:500 Length:500 Min. : 125.6 ## 1st Qu.:35.00 Class :character Class :character 1st Qu.: 2634.0 ## Median :50.00 Mode :character Mode :character Median : 5268.8 ## Mean :50.34 Mean : 6040.2 ## 3rd Qu.:66.00 3rd Qu.: 7264.7 ## Max. :80.00 Max. :412545.0 ## NA&#39;s :10 ## interes_en_politica frecuencia_de_voto ideologia_politica ## 4 : 56 Length:500 Length:500 ## 5 : 56 Class :character Class :character ## 8 : 56 Mode :character Mode :character ## 10 : 53 ## 6 : 49 ## 9 : 49 ## (Other):181 ## confianza_en_gobierno uso_de_redes_informarse participacion_protestas ## 6 : 59 Length:500 Length:500 ## 8 : 56 Class :character Class :character ## 10 : 54 Mode :character Mode :character ## 7 : 52 ## 1 : 50 ## 3 : 50 ## (Other):179 Note que la media y mediana de la edad son muy similares, mientras que en el caso de ingreso mensual, se alejan un poco más. Note también que el valor máximo en esta última variable se encuentra alejado del tercer cuartil. Todo esto lo podemos visualizar mejor en un gráfico de Caja y Bigotes. Caja y bigotes para la variable edad boxplot(datos$edad, horizontal=TRUE, col=&#39;steelblue&#39;, main=&quot;Boxplot de edad&quot;) Caja y bigotes para la variable Ingreso mensual # Desactivar notación científica (cuando las cifras son muy largas) options(scipen=999) # Generar el boxplot sin notación científica boxplot(datos$ingreso_mensual, horizontal=TRUE, col=&#39;cadetblue4&#39;, main=&quot;Boxplot de Ingreso Mensual&quot;) El gráfico se ve de esta manera por los valores extremos. Así se vería sin esos datos atípicos: # Desactivar notación científica options(scipen=999) # Generar boxplot sin valores extremos boxplot(datos$ingreso_mensual, horizontal=TRUE, col=&#39;cadetblue4&#39;, main=&quot;Boxplot de Ingreso Mensual (Sin Valores Extremos)&quot;, outline=FALSE) # Esto elimina los valores atípicos visualmente En esta ocasión, reemplazaremos los atípicos por el valor de la mediana a manera de imputación: # Calcular la mediana del ingreso mensual mediana &lt;- median(datos$ingreso_mensual, na.rm=TRUE) # Reemplazar valores atípicos con la mediana datos$ingreso_mensual &lt;- ifelse(datos$ingreso_mensual %in% boxplot.stats(datos$ingreso_mensual)$out, mediana, datos$ingreso_mensual) # Verificar con un nuevo boxplot boxplot(datos$ingreso_mensual, horizontal=TRUE, col=&#39;cadetblue4&#39;, main=&quot;Boxplot de Ingreso Mensual (Atípicos Reemplazados con Mediana)&quot;) 2.3.5 Exploración de variables: Representación en tablas: Tabla de Frecuencia para Nivel de Educación # Tabla de Frecuencia para Nivel de Educación tabla_educacion &lt;- table(datos$nivel_de_educacion) print(tabla_educacion) ## ## Posgrado Primaria Secundaria Universitaria ## 78 51 189 182 Tabla de Frecuencia para Ideología Política # Tabla de Frecuencia para Ideología Política tabla_ideologia &lt;- table(datos$ideologia_politica) print(tabla_ideologia) ## ## Centro Derecha Izquierda ## 181 156 153 Tabla de Frecuencia para interés en política # Tabla de Frecuencia para interés en política tabla_interes_pol &lt;- table(datos$interes_en_politica) print(tabla_interes_pol) ## ## 1 2 3 4 5 6 7 8 9 10 ## 46 44 47 56 56 49 44 56 49 53 Tabla de frecuencia agrupada para ingreso mensual # Determinar automáticamente el número de intervalos con la regla de Sturges num_intervals &lt;- nclass.Sturges(datos$ingreso_mensual) # Agrupar ingresos en intervalos automáticos datos$ingreso_grupo &lt;- cut(datos$ingreso_mensual, breaks = num_intervals, include.lowest = TRUE) # Crear la tabla de frecuencia tabla_ingreso &lt;- table(datos$ingreso_grupo) # Convertir en data frame para mejor presentación tabla_ingreso_df &lt;- as.data.frame(tabla_ingreso) colnames(tabla_ingreso_df) &lt;- c(&quot;Rango de Ingreso&quot;, &quot;Frecuencia&quot;) # Calcular la frecuencia relativa frecuencia_relativa &lt;- prop.table(tabla_ingreso) * 100 # Convertir a porcentaje tabla_ingreso_df$frecuencia_relativa &lt;- round(frecuencia_relativa, 2) # Agregar columna con % y redondear tabla_ingreso_df #Mostrar la tabla resultante ## Rango de Ingreso Frecuencia frecuencia_relativa ## 1 [113,1.38e+03] 52 10.61 ## 2 (1.38e+03,2.63e+03] 70 14.29 ## 3 (2.63e+03,3.88e+03] 56 11.43 ## 4 (3.88e+03,5.14e+03] 61 12.45 ## 5 (5.14e+03,6.39e+03] 89 18.16 ## 6 (6.39e+03,7.64e+03] 58 11.84 ## 7 (7.64e+03,8.89e+03] 60 12.24 ## 8 (8.89e+03,1.01e+04] 43 8.78 ## 9 (1.01e+04,1.14e+04] 0 0.00 ## 10 (1.14e+04,1.27e+04] 1 0.20 2.3.6 Gráficos: Nota: Encuentra aquí la guía de colores para tus gráficos &gt; **(guía de colores) Gráfico para la variable genero: ggplot(datos, aes(x = genero, fill = genero)) + geom_bar() + labs(title = &quot;Distribución de Género&quot;, x = &quot;Género&quot;, y = &quot;Frecuencia&quot;) + theme_minimal() Gráfico para la variable edad: ggplot(datos, aes(x = edad)) + geom_histogram(bins = 10, fill = &quot;steelblue&quot;, color = &quot;black&quot;, alpha = 0.7) + labs(title = &quot;Distribución de Edades&quot;, x = &quot;Edad&quot;, y = &quot;Frecuencia&quot;) + theme_minimal() Gráfico para ingreso mensual ggplot(datos, aes(x = ingreso_mensual)) + geom_histogram(bins = 10, fill = &quot;cyan4&quot;, color = &quot;black&quot;, alpha = 0.7) + labs(title = &quot;Distribución del Ingreso Mensual&quot;, x = &quot;Ingreso Mensual&quot;, y = &quot;Frecuencia&quot;) + theme_minimal() ## Warning: Removed 10 rows containing non-finite outside the scale range ## (`stat_bin()`). Gráfico para ideología ggplot(datos, aes(x = ideologia_politica, fill = ideologia_politica)) + geom_bar() + labs(title = &quot;Distribución de la Ideología Política&quot;, x = &quot;Ideología Política&quot;, y = &quot;Frecuencia&quot;) + theme_minimal() Gráfico circular para voto tabla_voto &lt;- table(datos$frecuencia_de_voto) df_voto &lt;- as.data.frame(tabla_voto) colnames(df_voto) &lt;- c(&quot;Frecuencia de Voto&quot;, &quot;Frecuencia&quot;) ggplot(df_voto, aes(x = &quot;&quot;, y = Frecuencia, fill = `Frecuencia de Voto`)) + geom_bar(stat = &quot;identity&quot;, width = 1) + coord_polar(&quot;y&quot;, start = 0) + labs(title = &quot;Frecuencia de Voto (Gráfico Circular)&quot;) + theme_void() 2.3.7 Análisis Bivariado diagrama de barras agrupadas genero vs votos # Crear gráfico de barras agrupadas ggplot(datos, aes(x = frecuencia_de_voto, fill = genero)) + geom_bar(position = &quot;dodge&quot;) + # &quot;dodge&quot; agrupa las barras labs(title = &quot;Frecuencia de Voto por Género&quot;, x = &quot;Frecuencia de Voto&quot;, y = &quot;Cantidad de Personas&quot;) + theme_minimal() diagrama de cajas y bigotes genero vs ingresos mensuales # Crear el boxplot de ingreso mensual según género ggplot(datos, aes(x = genero, y = ingreso_mensual, fill = genero)) + geom_boxplot() + # Agregar boxplot labs(title = &quot;Distribución del Ingreso Mensual por Género&quot;, x = &quot;Género&quot;, y = &quot;Ingreso Mensual&quot;) + theme_minimal() ## Warning: Removed 10 rows containing non-finite outside the scale range ## (`stat_boxplot()`). Diagrama de dispersión Edad vs ingreso # Relación entre edad e ingreso ggplot(datos, aes(x = edad, y = ingreso_mensual)) + geom_point(alpha = 0.5, color = &quot;blue&quot;) + geom_smooth(method = &quot;lm&quot;, color = &quot;red&quot;) + theme_minimal() + ggtitle(&quot;Relación entre Edad e Ingreso&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## Warning: Removed 10 rows containing non-finite outside the scale range ## (`stat_smooth()`). ## Warning: Removed 10 rows containing missing values or values outside the scale range ## (`geom_point()`). Matriz de correlación entre variables numéricas #Correlación entre variables numéricas # Cargar librería necesaria library(corrplot) ## corrplot 0.95 loaded # Seleccionar solo las variables numéricas de interés datos_correlacion &lt;- datos[, c(&quot;edad&quot;, &quot;ingreso_mensual&quot;)] # Calcular la matriz de correlación matriz_cor &lt;- cor(datos_correlacion, use = &quot;complete.obs&quot;) # Mostrar matriz de correlación en consola print(matriz_cor) ## edad ingreso_mensual ## edad 1.00000000 0.04279635 ## ingreso_mensual 0.04279635 1.00000000 2.3.8 Conlusiones El Análisis Exploratorio de Datos (EDA) realizado sobre la encuesta de opinión pública permitió identificar patrones y relaciones clave entre variables sociodemográficas y políticas. A través del análisis de distribuciones, correlaciones y visualizaciones, se detectaron valores faltantes y valores atípicos. El EDA es un paso esencial y no opcional en cualquier investigación cuantitativa, ya que proporciona una comprensión profunda de los datos y permite tomar decisiones informadas sobre el tratamiento de variables y la aplicación de modelos. Hallazgos Edad : La distribución de edades es relativamente uniforme, sin concentraciones extremas en grupos específicos. Género: Se observó una distribución equilibrada de género en la muestra. El análisis de caja y bigotes mostró que existen diferencias en los ingresos según el género, con una mediana salarial mayor en ciertos grupos. Nivel de Educación: La mayoría de los encuestados tienen estudios universitarios, seguidos de aquellos con educación secundaria. . Ingreso Mensual: Se identificaron valores atípicos, lo que indica la presencia de individuos con ingresos significativamente mayores que el resto. La distribución de ingresos no es homogénea, con una concentración en los rangos medios y menores diferencias por edad. Frecuencia de Voto️ : La mayoría de los encuestados afirmaron votar siempre o a veces, con pocos casos de abstención total. "],["distribuciones-muestrales.html", "Lección 3 Distribuciones Muestrales 3.1 Estadísticos: 3.2 Comandos dpqr para distribuciones de probabilidad 3.3 Distribuciones de probabilidad discretas 3.4 Distribuciones de probabilidad continuas 3.5 Distribuciones muestrales: Simulaciones de múltiples muestras", " Lección 3 Distribuciones Muestrales En esta sección exploraremos las principales distribuciones de probabilidad utilizadas en estadistica, su interpretacion, su aplicacion en R y la manera en que pueden ser visualizadas. 3.1 Estadísticos: Con estos ejercicios vamos a simular que calculamos estadísticos para algunas variables. 3.1.1 Datos númericos (media, varianza y desviación estándar) Crear una secuencia de datos numéricos x &lt;- seq(1, 5, length = 100) #Crear un vector 100 números desde el 1 hasta el 5 x ## [1] 1.000000 1.040404 1.080808 1.121212 1.161616 1.202020 1.242424 1.282828 ## [9] 1.323232 1.363636 1.404040 1.444444 1.484848 1.525253 1.565657 1.606061 ## [17] 1.646465 1.686869 1.727273 1.767677 1.808081 1.848485 1.888889 1.929293 ## [25] 1.969697 2.010101 2.050505 2.090909 2.131313 2.171717 2.212121 2.252525 ## [33] 2.292929 2.333333 2.373737 2.414141 2.454545 2.494949 2.535354 2.575758 ## [41] 2.616162 2.656566 2.696970 2.737374 2.777778 2.818182 2.858586 2.898990 ## [49] 2.939394 2.979798 3.020202 3.060606 3.101010 3.141414 3.181818 3.222222 ## [57] 3.262626 3.303030 3.343434 3.383838 3.424242 3.464646 3.505051 3.545455 ## [65] 3.585859 3.626263 3.666667 3.707071 3.747475 3.787879 3.828283 3.868687 ## [73] 3.909091 3.949495 3.989899 4.030303 4.070707 4.111111 4.151515 4.191919 ## [81] 4.232323 4.272727 4.313131 4.353535 4.393939 4.434343 4.474747 4.515152 ## [89] 4.555556 4.595960 4.636364 4.676768 4.717172 4.757576 4.797980 4.838384 ## [97] 4.878788 4.919192 4.959596 5.000000 Media mean(x) ## [1] 3 Desviación estándar sd(x) ## [1] 1.172181 3.1.2 Datos categóricos (proporción) En R, puedes crear un vector dicotómico que represente, por ejemplo, si una persona tiene o no tiene acceso a Internet en su hogar Vector categórico # Crear un vector categórico con &quot;S&quot; (Sí) y &quot;N&quot; (No) acceso_internet &lt;- c(&quot;S&quot;, &quot;S&quot;, &quot;N&quot;, &quot;S&quot;, &quot;N&quot;, &quot;S&quot;, &quot;S&quot;, &quot;N&quot;, &quot;S&quot;, &quot;N&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;N&quot;, &quot;N&quot;) Proporción: Función mean # Crear un vector categórico con &quot;S&quot; (Sí) y &quot;N&quot; (No) acceso_internet &lt;- c(&quot;S&quot;, &quot;S&quot;, &quot;N&quot;, &quot;S&quot;, &quot;N&quot;, &quot;S&quot;, &quot;S&quot;, &quot;N&quot;, &quot;S&quot;, &quot;N&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;N&quot;, &quot;N&quot;) # Calcular la proporción de &quot;S&quot; y &quot;N&quot; prop_S2 &lt;- mean(acceso_internet == &quot;S&quot;) # Proporción de &quot;S&quot; prop_N2 &lt;- mean(acceso_internet == &quot;N&quot;) # Proporción de &quot;N&quot; Proporciones: prop_S2 ## [1] 0.6 prop_N2 ## [1] 0.4 **Cuando se representa con (1 = Sí, 0 = No). Luego, puedes calcular la proporción de cada categoría solo calculando la media, # Crear un vector dicotómico (1 = Tiene acceso a Internet, 0 = No tiene) y &lt;- c(1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,0, 1, 1, 1, 1) Proporciones: prop_1 &lt;- mean(acceso_internet == 1) # Proporción de personas con acceso prop_0 &lt;- mean(acceso_internet == 0) # Proporción de personas sin acceso prop_1 ## [1] 0 prop_0 ## [1] 0 3.2 Comandos dpqr para distribuciones de probabilidad R proporciona cuatro funciones fundamentales para manejar distribuciones de probabilidad, se utilizan comando + distribución*: d: Calcula la funcion de densidad de probabilidad (PDF) o la funcion de masa de probabilidad (PMF) para una distribucion. p: Calcula la funcion de distribucion acumulada (CDF), que nos dice la probabilidad de obtener un valor menor o igual a un punto dado. q: Calcula cuantiles o percentiles de la distribucion. r: Genera valores aleatorios a partir de la distribucion especificada. 3.2.1 d (densidad): Funcion de Densidad de Probabilidad (PDF) La densidad de probabilidad es una función matemática que describe la probabilidad relativa de que una variable aleatoria tome un valor específico dentro de un rango. En el caso de una distribución continua, como la normal, la probabilidad exacta de un solo punto es cero, por lo que en su lugar analizamos la densidad de probabilidad. Ejemplo, creamos un vector numéricos: x &lt;- seq(1, 5, length = 100) x ## [1] 1.000000 1.040404 1.080808 1.121212 1.161616 1.202020 1.242424 1.282828 ## [9] 1.323232 1.363636 1.404040 1.444444 1.484848 1.525253 1.565657 1.606061 ## [17] 1.646465 1.686869 1.727273 1.767677 1.808081 1.848485 1.888889 1.929293 ## [25] 1.969697 2.010101 2.050505 2.090909 2.131313 2.171717 2.212121 2.252525 ## [33] 2.292929 2.333333 2.373737 2.414141 2.454545 2.494949 2.535354 2.575758 ## [41] 2.616162 2.656566 2.696970 2.737374 2.777778 2.818182 2.858586 2.898990 ## [49] 2.939394 2.979798 3.020202 3.060606 3.101010 3.141414 3.181818 3.222222 ## [57] 3.262626 3.303030 3.343434 3.383838 3.424242 3.464646 3.505051 3.545455 ## [65] 3.585859 3.626263 3.666667 3.707071 3.747475 3.787879 3.828283 3.868687 ## [73] 3.909091 3.949495 3.989899 4.030303 4.070707 4.111111 4.151515 4.191919 ## [81] 4.232323 4.272727 4.313131 4.353535 4.393939 4.434343 4.474747 4.515152 ## [89] 4.555556 4.595960 4.636364 4.676768 4.717172 4.757576 4.797980 4.838384 ## [97] 4.878788 4.919192 4.959596 5.000000 mean(x) ## [1] 3 sd(x) ## [1] 1.172181 Usamos la función d + la distribución esta funcion devuelve la densidad de probabilidad en un punto especifico de la distribucion normal estandar. Nos dice que tan probable es que un valor especifico ocurra. Obtendremos las probabilidades para cada valor de x: #Aquí se utiliza la función d: densidad &lt;- dnorm(x, mean = 3 , sd = 1) densidad ## [1] 0.05399097 0.05848724 0.06325461 0.06829898 0.07362533 0.07923761 ## [7] 0.08513860 0.09132982 0.09781147 0.10458224 0.11163931 0.11897819 ## [13] 0.12659268 0.13447478 0.14261464 0.15100051 0.15961869 0.16845351 ## [19] 0.17748736 0.18670064 0.19607183 0.20557752 0.21519246 0.22488967 ## [25] 0.23464051 0.24441479 0.25418095 0.26390617 0.27355653 0.28309726 ## [31] 0.29249286 0.30170735 0.31070449 0.31944801 0.32790184 0.33603039 ## [37] 0.34379874 0.35117292 0.35812016 0.36460914 0.37061018 0.37609553 ## [43] 0.38103951 0.38541877 0.38921247 0.39240239 0.39497314 0.39691225 ## [49] 0.39821028 0.39886088 0.39886088 0.39821028 0.39691225 0.39497314 ## [55] 0.39240239 0.38921247 0.38541877 0.38103951 0.37609553 0.37061018 ## [61] 0.36460914 0.35812016 0.35117292 0.34379874 0.33603039 0.32790184 ## [67] 0.31944801 0.31070449 0.30170735 0.29249286 0.28309726 0.27355653 ## [73] 0.26390617 0.25418095 0.24441479 0.23464051 0.22488967 0.21519246 ## [79] 0.20557752 0.19607183 0.18670064 0.17748736 0.16845351 0.15961869 ## [85] 0.15100051 0.14261464 0.13447478 0.12659268 0.11897819 0.11163931 ## [91] 0.10458224 0.09781147 0.09132982 0.08513860 0.07923761 0.07362533 ## [97] 0.06829898 0.06325461 0.05848724 0.05399097 Graficar la densidad (probabilidad para cada valor de x): plot(x, densidad, type = &quot;l&quot;, col = &quot;blue&quot;, main = &quot;Densidad de Probabilidad Normal&quot;, ylab = &quot;Densidad&quot;, xlab = &quot;Valores&quot;) En el grafico, los valores cercanos a la media (0) tienen mayor probabilidad. 3.2.2 p (probabilidad acumulada): Funcion de Distribucion Acumulada: Esta funcion devuelve la probabilidad acumulada de que un valor sea menor o igual a un punto dado. #Probabilidad acumulada Z hasta 1.96 pnorm(1.96, mean=0, sd=1) ## [1] 0.9750021 La probabilidad acumulada hasta que Z valga 1.96 es del 0.975. Recuerde que estamos hablando de una distribución Z porque usamos la función p + norm (normal) con media = o y desviación = 1. Si pnorm(1.96, mean=0, sd=1) da 0.975, significa que el 97.5% de los valores en una normal estandar son menores a 1.96 en otras palabras. 3.2.3 q (cuartiles - valores de la variable x): Cuantiles o Percentiles Esta funcion devuelve el valor correspondiente a un percentil dado, no aroja probabilidad, si no, el valor que tomaría X de acuerdo a la posición percentil. Ejemplo: qnorm(0.975, mean = 0, sd = 1) ## [1] 1.959964 Note que esta función hace lo contrario a la anterior, Le ingresamos una probabilidad y nos arroja el valor de x, en este caso Z 3.2.4 r (ramdom values): Generacion de Valores Aleatorios Esta funcion genera valores aleatorios de una distribucion con los parametros dados, en este caso normal: set.seed(123) # Para reproducibilidad, para que se generen siempre los mismos valores, si no se usa, cada vez que ejecute las líneas de código, se crearán valores aleatorios nuevos. datos = rnorm(100, mean = 0, sd = 1) datos ## [1] -0.560475647 -0.230177489 1.558708314 0.070508391 0.129287735 ## [6] 1.715064987 0.460916206 -1.265061235 -0.686852852 -0.445661970 ## [11] 1.224081797 0.359813827 0.400771451 0.110682716 -0.555841135 ## [16] 1.786913137 0.497850478 -1.966617157 0.701355902 -0.472791408 ## [21] -1.067823706 -0.217974915 -1.026004448 -0.728891229 -0.625039268 ## [26] -1.686693311 0.837787044 0.153373118 -1.138136937 1.253814921 ## [31] 0.426464221 -0.295071483 0.895125661 0.878133488 0.821581082 ## [36] 0.688640254 0.553917654 -0.061911711 -0.305962664 -0.380471001 ## [41] -0.694706979 -0.207917278 -1.265396352 2.168955965 1.207961998 ## [46] -1.123108583 -0.402884835 -0.466655354 0.779965118 -0.083369066 ## [51] 0.253318514 -0.028546755 -0.042870457 1.368602284 -0.225770986 ## [56] 1.516470604 -1.548752804 0.584613750 0.123854244 0.215941569 ## [61] 0.379639483 -0.502323453 -0.333207384 -1.018575383 -1.071791226 ## [66] 0.303528641 0.448209779 0.053004227 0.922267468 2.050084686 ## [71] -0.491031166 -2.309168876 1.005738524 -0.709200763 -0.688008616 ## [76] 1.025571370 -0.284773007 -1.220717712 0.181303480 -0.138891362 ## [81] 0.005764186 0.385280401 -0.370660032 0.644376549 -0.220486562 ## [86] 0.331781964 1.096839013 0.435181491 -0.325931586 1.148807618 ## [91] 0.993503856 0.548396960 0.238731735 -0.627906076 1.360652449 ## [96] -0.600259587 2.187332993 1.532610626 -0.235700359 -1.026420900 Se crearon 100 números aleatorios que siguen una distribución normal estándar. set.seed() es una función en R que establece una semilla aleatoria para la generación de números pseudoaleatorios. Esto significa que garantiza que los resultados de cálculos aleatorios sean reproducibles cada vez que se ejecuta el código. Si no se fija una semilla con set.seed(), cada vez que ejecutes el código obtendrás diferentes valores aleatorios. hist(datos, breaks = 30, col = &quot;lightblue&quot;, main = &quot;Muestra Aleatoria de distribución Normal&quot;, xlab = &quot;Valores&quot;) Aqui generamos 1000 valores aleatorios de una normal estandar y los visualizamos en un histograma. 3.3 Distribuciones de probabilidad discretas A continuacion, exploramos tres distribuciones discretas: Bernoulli, Binomial y Poisson. 3.3.1 Distribucion de Bernoulli La distribucion de Bernoulli modela experimentos con solo dos posibles resultados: exito (1) o fracaso (0). La funcion de masa de probabilidad (PMF) es: \\[ P(X = x) = p^x (1-p)^{1-x}, \\quad x \\in \\{0,1\\} \\] p &lt;- 0.5 # Probabilidad de exito x &lt;- c(0, 1) densidad_bernoulli &lt;- dbinom(x, size = 1, prob = p) barplot(densidad_bernoulli, names.arg = x, col = &quot;steelblue&quot;, main = &quot;Distribucion de Bernoulli&quot;, ylab = &quot;Probabilidad&quot;, xlab = &quot;Valores&quot;) 3.3.2 Distribucion Binomial La distribucion binomial modela el numero de exitos en n ensayos independientes de Bernoulli con probabilidad p. Su PMF es: \\[ P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}, \\quad k = 0,1,\\dots,n \\] densidad_binomial &lt;- dbinom(0:10, size = 10, prob = 0.5) # size = número de ensayos y prob = Probabilidad de exito barplot(densidad_binomial, names.arg = 0:10, col = &quot;steelblue&quot;, main = &quot;Distribucion Binomial&quot;, ylab = &quot;Probabilidad&quot;, xlab = &quot;Numero de exitos&quot;) 3.4 Distribuciones de probabilidad continuas 3.4.1 Distribucion Normal La distribucion normal es una de las mas utilizadas en estadistica debido a su presencia en fenomenos naturales y cientificos. Se caracteriza por dos parametros: - Media (mu): Indica el centro de la distribucion. - Desviacion estandar (sigma): Define la dispersion de los datos. La funcion de densidad de probabilidad para la distribucion normal es: \\[ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\] En R podemos visualizarla de la siguiente manera: x &lt;- seq(4, 8, length = 100) #Crear una secuencia de 100 números del -4 al 4 x ## [1] 4.000000 4.040404 4.080808 4.121212 4.161616 4.202020 4.242424 4.282828 ## [9] 4.323232 4.363636 4.404040 4.444444 4.484848 4.525253 4.565657 4.606061 ## [17] 4.646465 4.686869 4.727273 4.767677 4.808081 4.848485 4.888889 4.929293 ## [25] 4.969697 5.010101 5.050505 5.090909 5.131313 5.171717 5.212121 5.252525 ## [33] 5.292929 5.333333 5.373737 5.414141 5.454545 5.494949 5.535354 5.575758 ## [41] 5.616162 5.656566 5.696970 5.737374 5.777778 5.818182 5.858586 5.898990 ## [49] 5.939394 5.979798 6.020202 6.060606 6.101010 6.141414 6.181818 6.222222 ## [57] 6.262626 6.303030 6.343434 6.383838 6.424242 6.464646 6.505051 6.545455 ## [65] 6.585859 6.626263 6.666667 6.707071 6.747475 6.787879 6.828283 6.868687 ## [73] 6.909091 6.949495 6.989899 7.030303 7.070707 7.111111 7.151515 7.191919 ## [81] 7.232323 7.272727 7.313131 7.353535 7.393939 7.434343 7.474747 7.515152 ## [89] 7.555556 7.595960 7.636364 7.676768 7.717172 7.757576 7.797980 7.838384 ## [97] 7.878788 7.919192 7.959596 8.000000 densidad &lt;- dnorm(x, mean = 6, sd = 0.5) #obtener las densidades (p) de cada número para la distribución Normal estandar y guardarlos en el objeto &quot;densidad&quot; densidad ## [1] 0.0002676605 0.0003685906 0.0005042761 0.0006854197 0.0009255692 ## [6] 0.0012417246 0.0016550295 0.0021915444 0.0028830946 0.0037681796 ## [11] 0.0048929229 0.0063120326 0.0080897328 0.0103006160 0.0130303565 ## [16] 0.0163762131 0.0204472422 0.0253641367 0.0312585990 0.0382721634 ## [21] 0.0465543853 0.0562603283 0.0675473021 0.0805708292 0.0954798526 ## [26] 0.1124112370 0.1314836630 0.1527910596 0.1763957719 0.2023217069 ## [31] 0.2305477404 0.2610017025 0.2935552764 0.3280201494 0.3641457400 ## [36] 0.4016187924 0.4400650707 0.4790533174 0.5181015431 0.5566856162 ## [41] 0.5942500061 0.6302204191 0.6640179600 0.6950743503 0.7228476598 ## [46] 0.7468379475 0.7666021883 0.7817678624 0.7920446268 0.7972335586 ## [51] 0.7972335586 0.7920446268 0.7817678624 0.7666021883 0.7468379475 ## [56] 0.7228476598 0.6950743503 0.6640179600 0.6302204191 0.5942500061 ## [61] 0.5566856162 0.5181015431 0.4790533174 0.4400650707 0.4016187924 ## [66] 0.3641457400 0.3280201494 0.2935552764 0.2610017025 0.2305477404 ## [71] 0.2023217069 0.1763957719 0.1527910596 0.1314836630 0.1124112370 ## [76] 0.0954798526 0.0805708292 0.0675473021 0.0562603283 0.0465543853 ## [81] 0.0382721634 0.0312585990 0.0253641367 0.0204472422 0.0163762131 ## [86] 0.0130303565 0.0103006160 0.0080897328 0.0063120326 0.0048929229 ## [91] 0.0037681796 0.0028830946 0.0021915444 0.0016550295 0.0012417246 ## [96] 0.0009255692 0.0006854197 0.0005042761 0.0003685906 0.0002676605 plot(x, densidad, type = &quot;l&quot;, col = &quot;blue&quot;, main = &quot;Distribucion Normal&quot;, ylab = &quot;Densidad&quot;, xlab = &quot;Valores&quot;) 3.4.2 Distribucion Normal Estandar Es un caso especial de la normal con media 0 y desviacion estandar 1. x &lt;- seq(-4, 4, length = 100) densidad &lt;- dnorm(x, mean = 0, sd = 1) plot(x, densidad, type = &quot;l&quot;, col = &quot;red&quot;, main = &quot;Densidad de la distribución Normal Estandar&quot;, ylab = &quot;Densidad&quot;, xlab = &quot;Valores&quot;) 3.4.3 Distribucion t de Student Esta distribucion se utiliza cuando el tamano de la muestra es pequeno y la varianza poblacional es desconocida. Su funcion de densidad es: \\[ f(t) = \\frac{\\Gamma((v+1)/2)}{\\sqrt{v\\pi} \\Gamma(v/2)} \\left( 1 + \\frac{t^2}{v} \\right)^{-(v+1)/2} \\] donde \\(v\\) es el numero de grados de libertad. x &lt;- seq(-4, 4, length = 100) densidad_t &lt;- dt(x, df = 10) #df significa: Grados de libertad plot(x, densidad_t, type = &quot;l&quot;, col = &quot;green&quot;, main = &quot;Distribucion t de Student&quot;, ylab = &quot;Densidad&quot;, xlab = &quot;Valores&quot;) Los grados de libertad en la distribución t: Para visualizar la convergencia de la distribucion t a la normal estandar a medida que aumentan los grados de libertad, graficamos ambas en la misma figura. x &lt;- seq(-4, 4, length = 100) # Definir los grados de libertad grados_libertad &lt;- c(1, 5, 28) colores &lt;- c(&quot;red&quot;, &quot;green&quot;, &quot;orange&quot;) Graficando en comparación con la distribución Normal Estándar: # Graficar la distribucion normal estandar plot(x, dnorm(x, mean = 0, sd = 1), type = &quot;l&quot;, col = &quot;black&quot;, lwd = 2, main = &quot;Comparacion entre la Distribucion t y la Normal Estandar&quot;, ylab = &quot;Densidad&quot;, xlab = &quot;Valores&quot;, ylim = c(0, 0.45)) # Agregar las distribuciones t con diferentes grados de libertad for (i in 1:length(grados_libertad)) { lines(x, dt(x, df = grados_libertad[i]), col = colores[i], lwd = 2) } # Agregar una leyenda legend(&quot;topright&quot;, legend = c(&quot;Normal Estandar&quot;, paste(&quot;t (df=&quot;, grados_libertad, &quot;)&quot;)), col = c(&quot;black&quot;, colores), lwd = 2) 3.4.4 Distribucion Chi-cuadrado Esta distribucion se usa en pruebas de hipotesis y analisis de varianza. Se obtiene como la suma de los cuadrados de \\(k\\) variables aleatorias normales estandar. Su funcion de densidad es: \\[ f(x) = \\frac{x^{(k/2)-1} e^{-x/2}}{2^{k/2} \\Gamma(k/2)} \\] x &lt;- seq(0, 20, length = 100) densidad_chi2 &lt;- dchisq(x, df = 5) #df significa grados de libertad plot(x, densidad_chi2, type = &quot;l&quot;, col = &quot;purple&quot;, main = &quot;Distribucion Chi-cuadrado&quot;, ylab = &quot;Densidad&quot;, xlab = &quot;Valores&quot;) 3.4.5 Distribucion F Se usa para comparar varianzas en pruebas de hipotesis. Es la razon de dos distribuciones Chi-cuadrado divididas por sus respectivos grados de libertad: \\[ F = \\frac{(\\chi^2_{df1} / df1)}{(\\chi^2_{df2} / df2)} \\] x &lt;- seq(0, 5, length = 100) densidad_f &lt;- df(x, df1 = 5, df2 = 10) #df1 y df2 son lso grados de libertad plot(x, densidad_f, type = &quot;l&quot;, col = &quot;orange&quot;, main = &quot;Distribucion F&quot;, ylab = &quot;Densidad&quot;, xlab = &quot;Valores&quot;) 3.5 Distribuciones muestrales: Simulaciones de múltiples muestras Las distribuciones muestrales describen la variabilidad de un estadístico muestral (como la media, proporción o varianza) a través de diferentes muestras tomadas de una misma población. Diferencia clave Mientras que una distribución de probabilidad describe cómo se comporta una sola variable aleatoria, Una distribución muestral describe cómo varía un estadístico, como la media muestral, al tomar muchas muestras. 3.5.1 Simulación de la distribución muestral de la media set.seed(123) #Sembrar semilla para que solo se generen valores aletorios una vez medias &lt;- numeric(1000) # Vector vacío para guardar las medias Se crean 1000 muestras de 30 observaciones cada, cada una a partir de una distribución normal com media 50 y desviación estándar de 10. Luego, se guardan todas las medias muestrales. #Esto es un blucle: acción repetitiva: for (i in 1:1000) { #Para cada i desde 1 hasta 1000, generar una muestra a partir de una distribución normal muestra &lt;- rnorm(30, mean = 50, sd = 10) # Cada muestra tiene 30 observaciones y sigue distribución normal con media 50 y desvición estándar de 10 medias[i] &lt;- mean(muestra) # Guardamos las medias muestrales en el vector medias } head(medias) #Mostrar las primeras medias generadas ## [1] 49.52896 51.78338 50.24420 49.06111 48.16420 51.53717 Graficando la media de cada muestra en un histograma: hist(medias, breaks = 30, col = &quot;lightblue&quot;, probability = TRUE, main = &quot;Distribucion Muestral de la Media&quot;, xlab = &quot;Media Muestral&quot;) lines(density(medias), col = &quot;red&quot;, lwd = 2) # Agregamos la curva de densidad La forma de campana describe cómo el histograma se aproxima a una distribución normal. 3.5.2 Simulación de la distribucion Muestral de la Varianza La distribucion de la varianza muestral sigue una distribucion chi-cuadrado. Ahora vamos a generar nuevamente 1000 muestras de tamaño 30 que sigan distribución normal con media 50 y desviación estándar de 30: set.seed(123) #Semilla para que no se generen valores diferentes cada vez que se corra el código varianzas &lt;- numeric(1000) # Crear vector númerico con el tamaño de las n muestras #Crear en bucle las 1000 muestras y calcular la varianza de cada una for (i in 1:1000) { muestra &lt;- rnorm(30, mean = 50, sd = 10) #generar muestras normales con media 50 y desviación estándar de 10 varianzas[i] &lt;- var(muestra) #Guardar las varianzas de cada muestra. } Graficando en un histograma las 1000 varianzas calculadas (una para cada muestra): hist(varianzas, breaks = 30, col = &quot;pink&quot;, probability = TRUE, main = &quot;Distribucion Muestral de la Varianza&quot;, xlab = &quot;Varianza Muestral&quot;) lines(density(varianzas), col = &quot;red&quot;, lwd = 2) Se puede apreciar la forma muy similar a la distribución chi cuadrada. 3.5.3 Simulación de la distribucion Muestral de la Proporción Si tomamos muestras de una población binomial, la proporcion de “exitos” en cada muestra sigue una distribucion aproximadamente normal si el tamaño de la muestra es suficientemente grande. set.seed(123) poblacion &lt;- rbinom(10000, size = 1, prob = 0.4) # Poblacion binaria con p = 0.4 proporciones &lt;- numeric(1000)# Crear vector númerico con el tamaño de las n muestras Se crean 1000 muestras, cada una a partir de una distribución binomial com probabilidad de éxito de 0.4. Luego, se guardan todas las proporciones de éxito muestrales. for (i in 1:1000) { muestra &lt;- sample(poblacion, 50) proporciones[i] &lt;- mean(muestra) #Calcular la proporción de exitos en cada muestra } hist(proporciones, breaks = 30, col = &quot;lightgreen&quot;, probability = TRUE, main = &quot;Distribucion Muestral de la Proporcion&quot;, xlab = &quot;Proporcion Muestral&quot;) lines(density(proporciones), col = &quot;red&quot;, lwd = 2) Se puede apreciar como la distribución binomial se acerca mucho a la distribución normal. "],["intervalos-de-confianza.html", "Lección 4 Intervalos de confianza 4.1 MEDIA 4.2 PROPORCIÓN 4.3 ¿Cómo se aplica?: Caso simulado", " Lección 4 Intervalos de confianza Paquetes necesarios 4.1 MEDIA 4.1.1 Intervalos de confianza para la media Para calcular el intervalo de confianza para la media, se deben conocer tres componentes: la media muestral, el error muestral y el valor de la distribución correspondiente al nivel de confianza asignado para el intervalo. El intervalo de confianza para estimar la media poblacional \\(\\mu\\) se construye de la siguiente manera: \\[ IC_{\\mu} = (\\bar{X} - Z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + Z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}) \\] Para el caso con distribución t: \\[IC_{\\mu} = (\\bar{X} - t_{\\alpha/2,n-1gdl} \\cdot \\frac{s}{\\sqrt{n}} \\leq \\mu \\leq \\bar{X} + t_{\\alpha/2,n-1gdl} \\cdot \\frac{s}{\\sqrt{n}})\\] Veamos parte por parte cómo hacerlo: Calcular la Media muestral La media muestral: \\[\\bar{X}\\] es el promedio calculado a partir de una muestra aleatoria. En R disponemos de la función mean para calcularla facilmente a partir de un conjunto de datos. Calcular el Error muestral \\[ \\frac{\\sigma}{\\sqrt n}\\] \\(\\sigma\\) es la desviación estándar poblacional y \\(n\\) es el tamaño de la muestra. Cuando la desviación estándar poblacional no es conocida, se utiliza la desviación estándar muestral (\\(s\\)): \\[ \\frac{s}{\\sqrt n}.\\] Calcular el Valor Crítico Teniendo en cuenta los supuestos, podemos determinar si la media sigue una distribución Normal (Z) (datos normales, desviación estándar poblacional conocida y muestra lo suficientemente grande) o distribución t-student (t) (datos no normales, desviación estándar poblacional desconocida y muestra pequeña) También debemos recordar que los intervalos de confianza son aleatorios puesto que se contruyen a partir de una muestra aleatoria, por lo tanto, existe un nivel de confianza \\(1-\\alpha\\) y un margen de error conocido \\(\\alpha\\) para estimar el parámtero. Ese valor \\(\\alpha\\) se divide entre 2 para distribuirlo a cada lado del intervalo de confianza. Es por esto que, Una vez determinada la distribución apropiada para el caso, se define el valor crítico para \\(\\alpha/2\\): \\(Z_{\\alpha/2}\\) para el caso Normal \\(t_{\\alpha/2}\\) para el caso t-student Ya conocemos también las funciones d, p, q, r que nos permitían realizar operaciones a partir de las distribuciones de probabilidad d: Calcula la funcion de densidad de probabilidad (PDF) o la funcion de masa de probabilidad (PMF) para una distribucion. p: Calcula la funcion de distribucion acumulada (CDF), que nos dice la probabilidad de obtener un valor menor o igual a un punto dado. q: Calcula cuantiles o percentiles de la distribucion. r: Genera valores aleatorios a partir de la distribucion especificada. Para calcular el valor crítico utilizaremos la función q, que calcula el valor de Z o de t a partir de una probabilidad dada: Para el caso \\(1-\\alpha = 95%\\), con \\(\\alpha = 5\\% = 0.05\\): Distribución normal: qnorm(0.025, lower.tail = FALSE) ## [1] 1.959964 Distribución t con 9 grados de libertad (ejemplo): qt(0.025, df=9, lower.tail = FALSE) #df = Grados de libertad ## [1] 2.262157 Nota: el parámetro ´lower.tail = FALSE´ se utiliza para que el valor crítico sea el de la derecha (positivo). Ya sabemos que estas dos distribuciones son siméticas y el valor es el mismo para cada lado del intervalo_ Calcular el Intervalo de Confianza Entonces, para calcular el intervalo de confianza se debe tener la estructura: límite inferior (izquierda) del intervalo de confianza: limite_inf = media muestral - qdistribucion(valor correspondiente) * error_muestral Para el límite superior (derecha) del intervalo de confianza: limite_sup = media muestral + qdistribucion(valor correspondiente) * error_muestral 4.1.2 Ejemplo intervalo de confianza para media poblacional: Un grupo de investigadores quiere estimar el tiempo promedio que los ciudadanos de un país dedican diariamente a informarse con los noticieros. Se toma una muestra aleatoria de 1,500 personas, obteniendo una media muestral de 45 minutos diarios. Estudios previos indican que la desviación estándar poblacional es de 20 minutos. Calcular un intervalo de confianza del 95% para el tiempo promedio que la población dedica a informarse a través de noticieros. Primero, organizar los datos y guardarlos en objetos con los nombres que consideremos adecuados: # Datos x_barra &lt;- 45 # media muestral desv_est &lt;- 20 # desviación estándar poblacional n &lt;- 1500 # tamaño de muestra alpha &lt;- 0.05 Teniendo en cuenta el ejercicio, la media sigue en este caso una distribución Normal, ya que se trata de un amuestra grande y la desviación estándar poblacional es conocida. Ahora se debe determinar el valor crítico \\(Z_{\\alpha/2}\\) # Valor crítico Z z_alpha_2 &lt;- qnorm(0.025, lower.tail = FALSE) #El valor de Z para alpha/2 z_alpha_2 ## [1] 1.959964 Calcular el error, en este caso: $ $ # Error: error &lt;- desv_est / sqrt(n) #sqrt calcula la raiz #Tenga en cuenta que cada dato proporcionado por el ejercicio ya lo habíamos guardado con nombres apropiados. error ## [1] 0.5163978 Construir el ntervalo de confianza: # Intervalo de confianza ic_izquierda &lt;- x_barra - z_alpha_2 * error ic_derecha &lt;- x_barra + z_alpha_2 * error c(ic_izquierda, ic_derecha) #Esto permite concatenar los dos números para que se muestren juntos ## [1] 43.98788 46.01212 Respuesta: Con un 95% de confianza, el tiempo promedio que los ciudadanos dedican a informarse sobre política está entre 43.99 y 46.01 minutos 4.1.3 Prueba de hipótesis para la media Recordemos que: Una prueba de hipótesis es un procedimiento estadístico utilizado para tomar decisiones sobre un parámetro poblacional basándose en una muestra. Matemáticamente, se trata de evaluar la validez de una afirmación acerca de una población utilizando teoría de probabilidades y distribuciones muestrales El objetivo de una prueba de hipótesis es evaluar si los datos de una muestra proporcionan evidencia estadísticamente significativa para rechazar una hipótesis sobre la media poblacional Hipótesis nula \\(H_0\\) La hipótesis que se debe comprobar. Inicialmente se asume como verdadera. Hipótesis alternativa \\(H_1\\) Se establece como el “complemento” de \\(H_0\\) Prueba bilateral: \\(H_1: \\mu \\neq \\mu_0\\) Prueba unilateral derecha: \\(H_1: \\mu &gt; \\mu_0\\) Prueba unilateral izquierda: \\(H_A: \\mu &lt; \\mu_0\\) Seleccionar el estadístico de prueba Caso 1: Desviación estándar poblacional conocida (prueba Z) \\[ Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\] Caso 2: Desviación estándar poblacional desconocida (prueba t de Student) \\[ T = \\frac{\\bar{X} - \\mu}{S / \\sqrt{n}}, \\quad T \\sim t_{n-1} \\] Calcular el Valor o valores Críticos: Volvemos a utilizar las funcionas d, p, q, r para las distribuciones de probabilidad Nuevamente, teniendo en cuenta los supuestos, podemos determinar si la media sigue una distribución Normal (Z) (datos normales, desviación estándar poblacional conocida y muestra lo suficientemente grande) o distribución t-student (t) (datos no normales, desviación estándar poblacional desconocida y muestra pequeña) También debemos recordar que las pruebas de hipótesis tienen un nivel de significancia \\(\\alpha\\). Una vez determinada la distribución apropiada para el caso,y el tipo de prueba (bilateral o unilateral) se define el valor crítico para \\(\\alpha\\) o \\(\\alpha/2\\). Caso bilateral con \\(\\alpha = 5\\%\\) \\(H_1: \\mu \\neq \\mu_0\\) En este caso el valor \\(\\alpha\\) se divide entre 2 para encontrar los valores críticos de cada lado. Es decir, existen dos valores críticos. Ejemplo: Caso con distribución Normal \\(Z_{\\alpha/2}\\) (bilateral) qnorm(0.025) #Valor crítico por la izquierda ## [1] -1.959964 qnorm(0.025, lower.tail = FALSE) #Valor crítico por la derecha ## [1] 1.959964 Ejemplo: Caso con distribución t con 9 grados de libertad \\(t_{\\alpha/2,n-1 gdl}\\) (bilateral) #Valor crítico por la izquierda qt(0.025, df=9) #df = Grados de libertad ## [1] -2.262157 #Valor crítico por la derecha qt(0.025, df=9, lower.tail = FALSE) #df = Grados de libertad ## [1] 2.262157 Caso Unilateral cola derecha con \\(\\alpha = 5\\%\\) \\(H_1: \\mu &gt; \\mu_0\\) En este caso el valor \\(\\alpha\\) NO divide entre 2. Es decir, sólo se tiene un valor crítico por la derecha. Ejemplo: Caso con distribución Normal \\(Z_{\\alpha}\\) (Unilateral derecha) qnorm(0.05, lower.tail = FALSE) #Valor crítico por la derecha ## [1] 1.644854 Ejemplo: Caso con distribución t con 9 grados de libertal \\(t_{\\alpha,n-1 gdl}\\) (Unilateral derecha) qt(0.05, df= 9, lower.tail = FALSE) #Valor crítico por la derecha ## [1] 1.833113 Caso Unilateral cola izquierda con \\(\\alpha = 5\\%\\) \\(H_1: \\mu &lt; \\mu_0\\) En este caso el valor \\(\\alpha\\) NO divide entre 2. Es decir, sólo se tiene un valor crítico por la izquierda. Ejemplo: Caso con distribución Normal \\(Z_{\\alpha}\\) (Unilateral izquierda) qnorm(0.05) #Valor crítico por la izquierda ## [1] -1.644854 Ejemplo: Caso con distribución t con 9 grados de libertal \\(t_{\\alpha,n-1 gdl}\\) (Unilateral izquierda) qt(0.05, df= 9) #Valor crítico por la derecha ## [1] -1.833113 Calcular el p valor El p-valor es la probabilidad, bajo la suposición de que la hipótesis nula \\(H_0\\) es cierta, de obtener un valor de la estadística de prueba tan extremo o más extremo que el observado. En otras palabras, mide qué tan probable es el resultado muestral si \\(H_0\\) fuera verdadera. Aquí el comando utilizado es ´p´ para calcular la probabilidad: P valor para una prueba bilateral (se multiplica por 2 al ser de dos colas): pvalor_z &lt;- 2 * pnorm(abs(z), lower.tail = FALSE) # si se usa distribución Z pvalor_t &lt;- 2 * pt(abs(T), df= n-1 gdl, lower.tail = FALSE) # si se usa t de Student P valor Para una prueba Unilateral derecha: pvalor_z &lt;- pnorm(z, lower.tail = FALSE) pvalor_t &lt;- 1 - pt(T, df = n-1 gdl, lower.tail = FALSE) P valor Para una prueba Unilateral izquierda: pvalor_z &lt;- pnorm(Z) pvalor_t &lt;- 1 - pt(T, df = n-1 gdl) Recuerde que lower.tail = FALSE es para que calcule la probabilidad acumulada por la derecha_ Tomar la decisión Usando valor crítico: Se rechaza \\(H_0\\) si el estadístico de prueba cae fuera del intervalo definido por el o los valores críticos. Usando p-valor: Se rechaza \\(H_0\\) si \\(p \\leq \\alpha\\). 4.1.4 Ejemplo prueba de hipótesis para media poblacional: La pobreza puede influir en el desarrollo del lenguaje en la infancia debido a factores como el acceso limitado a recursos educativos y la menor exposición a vocabulario variado en el hogar. Se estima que, en el país la población general de niños de 5 años, el tamaño promedio del vocabulario es de 2,000 palabras, con una desviación estándar de 300 palabras. Sin embargo, no se sabe con certeza si este valor se mantiene en niños que crecen en contextos de pobreza. Para investigar esto, un grupo de psicólogos selecciona una muestra de 180 niños en situación de pobreza y encuentra que su vocabulario promedio es de 1,950 palabras. ¿El tamaño del vocabulario en niños de 5 años en pobreza del país es realmente 2,000 palabras, o hay evidencia de que es diferente? Tenga en cuenta una significancia del 5%. Plantear las hipótesis: \\[ \\begin{aligned} H_0\\!:\\! &amp; \\quad \\mu = 2000 \\quad \\text{(el tamaño promedio del vocabulario es 2000 palabras)} \\\\ H_A\\!:\\! &amp; \\quad \\mu \\neq 2000 \\quad \\text{(el tamaño promedio del vocabulario es diferente de 2000 palabras)} \\end{aligned} \\] Organizar los datos porporcionados: # Datos x_bar &lt;- 1950 # media muestral u &lt;- 2000 # valor de la hipótesis nula sigma &lt;- 300 # desviación estándar poblacional n &lt;- 180 # tamaño de la muestra alpha &lt;- 0.05 # nivel de significancia Calcular el estadístico de prueba: Al tratarse de una muestra grande con desviación estándar poblacional conocida, se utilizará Z. Z &lt;- (x_bar - u) / (sigma / sqrt(n)) Z ## [1] -2.236068 Calcular valores críticos. Al se runa prueba bilateral, alpha se divide entre 2 (Son dos valores críticos) # Valor crítico para prueba bilateral z_izquierda &lt;- qnorm(alpha / 2) z_izquierda ## [1] -1.959964 # Valor crítico para prueba bilateral z_derecha &lt;- qnorm(alpha / 2, lower.tail=FALSE) z_derecha ## [1] 1.959964 Calcular p valor # Valor crítico para prueba bilateral z_izquierda &lt;- qnorm(alpha / 2) z_izquierda ## [1] -1.959964 # p-valor p_valor &lt;- 2 * pnorm(abs(Z), lower.tail = FALSE) p_valor ## [1] 0.02534732 Decisión: Como Z = -2.23, cae en la región crítica, (menor a -1.96), se rechaza \\(H_0\\) El p-valor será aproximadamente 0.025, este valor es menor que \\(\\alpha= 0.05\\), se rechaza \\(H_0\\) (esta es otra manera de decidir) Respuesta: Hay suficiente evidencia estadística para afirmar que el tamaño promedio del vocabulario en niños de 5 años en situación de pobreza es significativamente diferente de 2,000 palabras. 4.2 PROPORCIÓN 4.2.1 Intervalo de confianza para la proporción Para calcular los intervalos de confianza para la proporción, se deben conocer tres componentes: la media muestral, el error muestral y el valor de la distribución correspondiente al nivel de confianza asignado para el intervalo. \\[ IC_{p} = (\\bar{p} - Z_{\\alpha/2} \\cdot \\sqrt \\frac{\\overline{p}(1-\\overline{p})}{n} \\leq p \\leq \\bar{p} + Z_{\\alpha/2} \\cdot \\sqrt \\frac{\\overline{p}(1-\\overline{p})}{n}) \\] Error muestral El error muestral de la proporción es \\[\\sqrt \\frac{\\overline{p}(1-\\overline{p})}{n}\\] donde \\(\\overline{p}\\) es la proporción muestral y \\(n\\) es el tamaño de la muestra. Calcular el Valor Crítico Teniendo en cuenta los supuestos, la proporción sigue una distribución Normal (Z) El valor \\(1-\\alpha\\) se divide entre 2 para distribuirlo a cada lado del intervalo de confianza y se busca el valor \\(Z_{\\alpha/2}\\). Para el caso \\(1-\\alpha = 95%\\), con \\(\\alpha = 5\\% = 0.05\\): Distribución normal: qnorm(0.025, lower.tail = FALSE) ## [1] 1.959964 El parámetro ´lower.tail = FALSE´ se utiliza para que el valor crítico sea el de la derecha (positivo). Ya sabemos que estas dos distribuciones son siméticas y el valor es el mismo para cada lado del intervalo_ Calcular el Intervalo de Confianza Entonces, para calcular el intervalo de confianza se debe tener la estructura: límite inferior (izquierda) del intervalo de confianza: limite_inf = proporción muestral - qnorm(valor correspondiente) * error_muestral Para el límite superior (derecha) del intervalo de confianza: limite_sup = proporción muestral + qnorm(valor correspondiente) * error_muestral 4.2.2 Ejemplo intervalo de confianza para la proporción Un estudio quiere analizar la brecha de acceso a servicios de salud mental en comunidades rurales. Se estima que, a nivel nacional, el 40% de los adultos tiene acceso a estos servicios ( = 0.40). Para evaluar si este porcentaje es menor en zonas rurales, un investigador encuestó a 300 adultos de comunidades rurales y encontró que 98 de ellos tienen acceso a atención psicológica. Calcular un intervalo de confianza del 95% para la proporción de adultos con acceso a servicios de salud mental en la muestra (rural) y analizar los resultados. Organizar los datos: # Datos n &lt;- 300 # tamaño de la muestra x &lt;- 98 # número de adultos con acceso p_gorro &lt;- x / n # proporción muestral alpha &lt;- 0.05 Teniendo en cuenta el ejercicio, la proporción sigue en este caso una distribución Normal, ya que se trata de una muestra grande. # Valor crítico Z z_alpha_2 &lt;- qnorm(0.025, lower.tail = FALSE) #El valor de Z para alpha/2 z_alpha_2 ## [1] 1.959964 # Error estándar error_p &lt;- sqrt(p_gorro * (1 - p_gorro) / n) # Intervalo de confianza izquierda = p_gorro - (z_alpha_2 * error_p) derecha = p_gorro + (z_alpha_2 * error_p) c(izquierda, derecha) ## [1] 0.2735960 0.3797374 4.3 ¿Cómo se aplica?: Caso simulado ¿El programa de becas de transporte garantiza condiciones académicas justas? En muchas universidades públicas, los estudiantes de estratos socioeconómicos bajos reciben una beca de transporte con el objetivo de reducir barreras de acceso y permanencia. La universidad desea evaluar si, en promedio, los estudiantes beneficiarios del programa mantienen un rendimiento académico acorde con el estándar institucional. El reglamento académico establece que un rendimiento promedio adecuado corresponde a una nota de 3.5 (en una escala de 0 a 5). Pregunta de investigación ¿El promedio poblacional de los estudiantes beneficiarios del programa de transporte es distinto de 3.5? Parámetro de interés Sea \\[\\mu\\] la media poblacional de la nota de los estudiantes beneficiarios del programa de transporte. Formulación de hipótesis \\[ H_0: \\mu = 3.5 \\] \\[ H_1: \\mu \\neq 3.5 \\] Se plantea una prueba bilateral, ya que no se asume a priori si el rendimiento es mayor o menor que el estándar. Nivel de significancia \\[ \\alpha = 0.05 \\] Base de datos Se tomó una muestra de 36 estudiantes beneficiarios. La base de datos contiene cinco variables relevantes para el análisis académico y social. datos &lt;- data.frame( id = 1:36, nota = c( 3.1, 3.2, 3.3, 3.3, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.6, 3.6, 3.6, 3.7, 3.7, 3.7, 3.8, 3.8, 3.8, 3.9, 3.9, 3.9, 3.5, 3.6, 3.7, 3.8, 3.4, 3.3, 3.2, 3.6, 3.7, 3.8, 3.9, 3.5, 3.6, 3.7 ), horas_estudio = c( 8, 9, 10, 11, 10, 12, 11, 12, 13, 14, 13, 15, 14, 15, 16, 14, 15, 16, 17, 16, 18, 17, 12, 13, 14, 15, 11, 10, 9, 14, 15, 16, 17, 13, 14, 15 ), edad = c( 18, 19, 19, 20, 20, 21, 20, 21, 22, 22, 21, 23, 22, 23, 24, 22, 23, 24, 25, 24, 26, 25, 21, 22, 23, 24, 20, 19, 18, 22, 23, 24, 25, 21, 22, 23 ), estrato = c( 1,1,2,2,2,3,2,3,3, 3,2,3,3,4,4,3,4,4, 4,4,5,4,2,3,3,4,2, 2,1,3,3,4,4,2,3,3 ), transporte = rep(&quot;Beneficiario&quot;, 36) ) head(datos) ## id nota horas_estudio edad estrato transporte ## 1 1 3.1 8 18 1 Beneficiario ## 2 2 3.2 9 19 1 Beneficiario ## 3 3 3.3 10 19 2 Beneficiario ## 4 4 3.3 11 20 2 Beneficiario ## 5 5 3.4 10 20 2 Beneficiario ## 6 6 3.4 12 21 3 Beneficiario Exploración inicial de la variable de interés Antes de realizar cualquier inferencia, se exploran los datos, en específico las notas. summary(datos$nota) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 3.100 3.400 3.600 3.581 3.725 3.900 hist(datos$nota, col = &quot;lightblue&quot;, main = &quot;Distribución de Notas&quot;, xlab = &quot;Notas&quot;) Verificación del supuesto de normalidad (Prueba de Shapiro-Wilk) H0: los datos provienen de una distribución normal H1: los datos no provienen de una distribución normal shapiro.test(datos$nota) ## ## Shapiro-Wilk normality test ## ## data: datos$nota ## W = 0.95383, p-value = 0.138 Si el p-valor es mayor que 0.05, no se rechaza la hipótesis de nula. Por tanto, el supuesto de normalidad es razonable para esta muestra. Prueba de hipótesis para la media poblacional Prueba t de Student para una muestra. Se compara la media muestral con el valor poblacional hipotético (3.5) prueba_t &lt;- t.test(datos$nota,mu = 3.5, alternative = &quot;two.sided&quot;,conf.level = 0.95) prueba_t ## ## One Sample t-test ## ## data: datos$nota ## t = 2.2218, df = 35, p-value = 0.03286 ## alternative hypothesis: true mean is not equal to 3.5 ## 95 percent confidence interval: ## 3.506949 3.654162 ## sample estimates: ## mean of x ## 3.580556 Interpretación estadística: El p-valor indica si la diferencia observada es estadísticamente significativa. Si el p-valor &lt; 0.05, se rechaza \\(H_0\\). Conclusión: Con un nivel de significancia del 5 %, la evidencia estadística indica que el promedio poblacional de notas de los estudiantes beneficiarios es significativamente distinto (y mayor de acuerdo con el intervalo de confianza) que el valor institucional de 3.5. En términos prácticos, el programa de becas de transporte parece estar asociado con un rendimiento académico adecuado. "],["análisis-bivariado-1.html", "Lección 5 Análisis Bivariado 5.1 Variable numérica (cuantitativa) y variable categórica (cualitativa) 5.2 Dos variables categóricas (cualitativas) 5.3 Dos variables numéricas (cuantitativas) 5.4 Conclusiones", " Lección 5 Análisis Bivariado Construcción de la base de datos simulada Contexto: La siguiente base de datos representa un conjunto de información simulada sobre 100 personas adultas entre 25 y 60 años, residentes en zonas urbanas y rurales de Colombia. Se incluyen variables relevantes para el estudio de desigualdad socioeconómica: ingresos, años de educación, nivel educativo, sexo, tipo de empleo y ubicación geográfica. Esta base nos servirá como hilo conductor para aplicar distintas pruebas estadísticas inferenciales. Tenga en cuenta que en esta ocasión estamos generando datos simulados. En caso de disponer una base de datos, el primer paso es importarla Cargar librerías necesarias Base de datos set.seed(2025) #Sembrar semilla para generar datos aleatorios una única vez datos &lt;- tibble( sexo = sample(c(&quot;Hombre&quot;, &quot;Mujer&quot;), 100, replace = TRUE), zona = sample(c(&quot;Urbana&quot;, &quot;Rural&quot;), 100, replace = TRUE, prob = c(0.6, 0.4)), educacion = sample(c(&quot;Básica&quot;, &quot;Media&quot;, &quot;Universitaria&quot;), 100, replace = TRUE, prob = c(0.3, 0.4, 0.3)), educacion_anios = case_when( educacion == &quot;Básica&quot; ~ sample(5:9, 100, replace = TRUE), educacion == &quot;Media&quot; ~ sample(10:12, 100, replace = TRUE), educacion == &quot;Universitaria&quot; ~ sample(13:18, 100, replace = TRUE) ), empleo = case_when( educacion == &quot;Básica&quot; ~ sample(c(&quot;Formal&quot;, &quot;Informal&quot;), 100, replace = TRUE, prob = c(0.2, 0.8)), educacion == &quot;Media&quot; ~ sample(c(&quot;Formal&quot;, &quot;Informal&quot;), 100, replace = TRUE, prob = c(0.4, 0.6)), educacion == &quot;Universitaria&quot; ~ sample(c(&quot;Formal&quot;, &quot;Informal&quot;), 100, replace = TRUE, prob = c(0.7, 0.3)) ), ingreso = 1000000 + 200000 * educacion_anios + rnorm(100, 0, 500000) ) %&gt;% mutate( educacion = fct_relevel(educacion, &quot;Básica&quot;, &quot;Media&quot;, &quot;Universitaria&quot;), empleo_formal = if_else(empleo == &quot;Formal&quot;, 1, 0) ) Diccionario de variables: Variable Tipo Descripción ingreso Cuantitativa Ingreso mensual en pesos colombianos sexo Cualitativa Género de la persona (Hombre, Mujer) educacion Cualitativa Nivel educativo alcanzado zona Cualitativa Zona de residencia (Urbana, Rural) empleo Cualitativa Tipo de empleo (Formal, Informal) educacion_anios Cuantitativa Años de educación formal empleo_formal Binaria Variable derivada: 1 si formal, 0 si informal Ver primeras filas de base de datos generada: head(datos) ## # A tibble: 6 × 7 ## sexo zona educacion educacion_anios empleo ingreso empleo_formal ## &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Hombre Rural Básica 6 Informal 1653509. 0 ## 2 Mujer Rural Media 11 Informal 4258150. 0 ## 3 Mujer Urbana Media 10 Informal 3786379. 0 ## 4 Mujer Rural Media 12 Formal 4263075. 1 ## 5 Hombre Urbana Básica 9 Informal 2315832. 0 ## 6 Hombre Rural Básica 9 Informal 2213163. 0 5.1 Variable numérica (cuantitativa) y variable categórica (cualitativa) 5.1.1 Prueba t para comparación de medias Se utiliza para comparar las medias de una variable cuantitativa entre dos grupos independientes. Recuerde que mientras más grande sea la muestra, la distribución t se aproxima a la distribución Normal Estándar. En casos aplicados, se utiliza la prueba t: no es tan común conocer las desviaciones estándar poblacionales Hipótesis: \\[ H_0: \\mu_1 = \\mu_2 \\quad vs \\quad H_1: \\mu_1 \\ne \\mu_2 \\] Estadístico de prueba: \\[ t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}} \\] Prueba t para comparar ingreso (numérica) según sexo (categórica: 2 categorías) t.test(ingreso ~ sexo, data = datos, var.equal = FALSE) ## ## Welch Two Sample t-test ## ## data: ingreso by sexo ## t = 0.2789, df = 97.426, p-value = 0.7809 ## alternative hypothesis: true difference in means between group Hombre and group Mujer is not equal to 0 ## 95 percent confidence interval: ## -326967.8 433892.2 ## sample estimates: ## mean in group Hombre mean in group Mujer ## 3248527 3195065 # Comando var.equal sirve para indicarle a R que las varianzas poblacionales son diferentes o iguales. Por defecto se asumen diferentes Note que la prueba t en R arroja: - Valor del estadístico de prueba t - Grados de libertad (df) - p-valor (cuando es menor al nivel de significancia (alfa) se rechaza Ho) - Hipótesis alternativa - Intervalo de confianza al 95% Interpretación: La prueba t para muestras independientes permite contrastar si el ingreso mensual promedio difiere significativamente entre hombres y mujeres. El valor-p obtenido fue 0.7809. Como este valor es mayor al nivel de significancia habitual de 0.05, NO se rechaza la hipótesis nula y concluimos que No existe una diferencia estadísticamente significativa entre los ingresos medios por sexo. 5.1.2 ANOVA (Análisis de varianza de un factor) Se utiliza para comparar las medias de más de dos grupos a partir de una variable categórica con más de dos categorías. Hipótesis: \\[ H_0: \\mu_1 = \\mu_2 = \\cdots = \\mu_k \\quad vs \\quad H_1: \\text{al menos una media es diferente} \\] Estadístico de prueba: \\[ F = \\frac{\\text{MS}_{\\text{entre}}}{\\text{MS}_{\\text{dentro}}} = \\frac{SC_{\\text{entre}} / (k - 1)}{SC_{\\text{dentro}} / (n - k)} \\] Anova para comparar ingreso (numérica) según nivel de educación (categórica: más de 2 categorías) prueba_anova &lt;- aov(ingreso ~ educacion, data = datos) #Hacer prueba y guardarla en un objeto summary(prueba_anova)#Visualizar el resultado ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## educacion 2 56284478322819 28142239161409 81.01 &lt;0.0000000000000002 *** ## Residuals 97 33697715181164 347399125579 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Interpretación: La prueba ANOVA se usa cuando se desea comparar la media de una variable cuantitativa en tres o más grupos. El valor-p del análisis fue menor a 0.05, por lo que se concluye que existen diferencias significativas en el ingreso promedio según el nivel educativo alcanzado. En consecuencia, podríamos afirmar que la educación tiene un efecto significativo sobre los ingresos. 5.2 Dos variables categóricas (cualitativas) 5.2.1 Prueba de diferencia de proporciones Se usa para comparar proporciones entre dos grupos independientes. Para comparar una misma proporción entre dos grupos independientes. Hipótesis: \\[ H_0: p_1 = p_2 \\quad vs \\quad H_1: p_1 \\ne p_2 \\] Estadístico de prueba: \\[ z = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p}(1 - \\hat{p})(\\frac{1}{n_1} + \\frac{1}{n_2})}} \\] Donde \\(\\hat{p} = \\frac{x_1 + x_2}{n_1 + n_2}\\) Diferencia de proporciones: Empleo formal según zona prop.test(table(datos$zona, datos$empleo_formal)) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: table(datos$zona, datos$empleo_formal) ## X-squared = 0.00000000000000000000000000000061054, df = 1, p-value = 1 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.2268736 0.1962778 ## sample estimates: ## prop 1 prop 2 ## 0.5217391 0.5370370 Interpretación: La prueba de diferencia de proporciones compara la proporción de empleo formal en las zonas urbana y rural. El valor-p fue mayor que 0.05. Por lo tanto, se no se rechaza la hipótesis nula: la proporción de empleo formal no varía significativamente entre zonas. 5.2.2 Prueba Chi-cuadrado Se utiliza para determinar si dos variables categóricas (de cualquier número de niveles) están asociadas. Generaliza la comparación a tablas mayores que 2x2. Hipótesis: \\[ H_0: \\text{Las variables son independientes} \\quad vs \\quad H_1: \\text{Las variables están asociadas} \\] Estadístico de prueba: \\[ \\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} \\] Donde \\(E_{ij} = \\frac{(\\text{total fila}_i)(\\text{total columna}_j)}{n}\\) Prueba chi-cuadrado: Educación vs. Tipo de empleo tabla_chi &lt;- table(datos$educacion, datos$empleo) #Se crea la tabla de contingencia chisq.test(tabla_chi) # Prueba Chi basada en la tabla de contingencia creada ## ## Pearson&#39;s Chi-squared test ## ## data: tabla_chi ## X-squared = 34.084, df = 2, p-value = 0.00000003969 Interpretación: La prueba chi-cuadrado evalúa si existe asociación entre dos variables cualitativas. En este caso, el valor-p menor a 0.05 indica una asociación significativa entre el nivel educativo y el tipo de empleo. Esto sugiere que las personas con mayor nivel educativo tienen más probabilidad de acceder al empleo formal. 5.3 Dos variables numéricas (cuantitativas) 5.3.1 Coeficiente de correlación de Pearson Mide la fuerza y dirección de la relación lineal entre dos variables cuantitativas. Hipótesis: \\[ H_0: \\rho = 0 \\quad vs \\quad H_1: \\rho \\ne 0 \\] Estadístico de prueba: \\[ t = \\frac{r \\sqrt{n - 2}}{\\sqrt{1 - r^2}} \\] Correlación: Años de educación vs. ingreso cor.test(datos$educacion_anios, datos$ingreso) ## ## Pearson&#39;s product-moment correlation ## ## data: datos$educacion_anios and datos$ingreso ## t = 14.768, df = 98, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7578810 0.8830005 ## sample estimates: ## cor ## 0.8306476 Interpretación: La correlación de Pearson evalúa la relación lineal entre dos variables cuantitativas. Se obtuvo un coeficiente de 0.83 con un valor-p menor a 0.05, lo que indica una correlación positiva y significativa. Es decir, a mayor número de años de educación, mayor ingreso mensual, en línea con teorías económicas de capital humano. 5.3.2 Regresión lineal simple Modelo para estimar una variable cuantitativa (Y) en función de otra (X): \\[ Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i \\] Se estima por mínimos cuadrados: \\[ \\hat{\\beta}_1 = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2}, \\quad \\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X} \\] Predecir ingreso por educación modelo &lt;- lm(ingreso ~ educacion_anios, data = datos) #correr modelo y guardarlo summary(modelo) #Resumen ## ## Call: ## lm(formula = ingreso ~ educacion_anios, data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1248215 -370080 -22128 285160 1261533 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 717475 177838 4.034 0.000109 *** ## educacion_anios 223297 15120 14.768 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 533500 on 98 degrees of freedom ## Multiple R-squared: 0.69, Adjusted R-squared: 0.6868 ## F-statistic: 218.1 on 1 and 98 DF, p-value: &lt; 0.00000000000000022 Interpretación: El modelo de regresión lineal simple estima la relación entre los años de educación y el ingreso mensual. El coeficiente de pendiente indica que por cada año adicional de educación, el ingreso mensual aumenta en promedio en aproximadamente 200 mil pesos. El valor-p asociado al coeficiente de educacion_anios es significativo, lo que respalda la utilidad predictiva del modelo. El R² indica qué proporción de la variabilidad del ingreso se explica por la educación formal. 5.4 Conclusiones Cada una de las pruebas utilizadas respondió a preguntas diferentes sobre la desigualdad: La prueba t evidenció que no existe una brecha de género en la población estudiada. El ANOVA mostró que los ingresos difieren significativamente por nivel educativo. La chi-cuadrado mostró asociación entre educación y empleo. La correlación validó la relación positiva entre educación e ingreso. La regresión lineal planteó que la educación tiene un efecto significativo sobre el ingreso. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
